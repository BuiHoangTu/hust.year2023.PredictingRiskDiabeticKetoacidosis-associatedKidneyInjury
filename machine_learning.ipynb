{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Drop the first 3 columns (ids)\n",
    "df = dfData38.drop(columns=[\"subject_id\", \"hadm_id\", \"stay_id\"])\n",
    "\n",
    "# Encode categorical variables\n",
    "df = pd.get_dummies(df, columns=[\"dka_type\", \"gender\", \"race\", \"liver_disease\"])\n",
    "\n",
    "# remove space in column name\n",
    "# df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "# Fill missing values (if any) # TODO: fill with K-neibor\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df.drop(columns=[\"akd\"])\n",
    "y = df[\"akd\"]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define parameters for XGBoost\n",
    "params = {\n",
    "    \"max_depth\": 100,  # maximum depth of the tree\n",
    "    \"learning_rate\": 0.01,  # learning rate\n",
    "    # 'objective': 'multi:softmax',  # objective function\n",
    "    \"num_class\": len(y.unique()),  # number of classes\n",
    "    \"eval_metric\": \"merror\",  # evaluation metric\n",
    "}\n",
    "\n",
    "# Convert training and testing data to DMatrix format\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_rounds = 1000  # number of boosting rounds\n",
    "model = xgb.train(params, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "\n",
    "# Predict on the testing data\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_binary)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred_binary)\n",
    "recall = metrics.recall_score(y_test, y_pred_binary)\n",
    "f1 = metrics.f1_score(y_test, y_pred_binary)\n",
    "\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "    yticklabels=[\"Actual Negative\", \"Actual Positive\"],\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Feature selection using LassoCV\n",
    "lasso_cv = LassoCV(cv=5, random_state=7)\n",
    "lasso_cv.fit(X, y)\n",
    "selected_features = X.columns[lasso_cv.coef_ != 0]\n",
    "lasso_cv.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# Splitting data into training and validation cohorts\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X[selected_features], y, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "# Model selection and evaluation\n",
    "models = {\n",
    "    \"XGBoost\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Light BGM\": GradientBoostingClassifier(),  # Assuming Light BGM is Light Gradient Boosting Machine\n",
    "    \"Ada Boost\": AdaBoostClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Multi-layer Perceptron\": MLPClassifier(),\n",
    "    \"Complement Naive Bayes\": ComplementNB(),\n",
    "    \"Support Vector Machine\": SVC(probability=True),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_auc = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=KFold(n_splits=10, shuffle=True, random_state=42),\n",
    "        scoring=\"roc_auc\",\n",
    "    )\n",
    "    avg_auc = np.mean(cv_scores)\n",
    "    if avg_auc > best_auc:\n",
    "        best_auc = avg_auc\n",
    "        best_model = model\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_valid)\n",
    "y_pred_proba = best_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "# Model evaluation\n",
    "auc = roc_auc_score(y_valid, y_pred_proba)\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_valid, y_pred).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"AUC: {auc}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "\n",
    "# Feature importance\n",
    "if hasattr(best_model, \"feature_importances_\"):\n",
    "    feature_importance = pd.DataFrame(\n",
    "        {\"Feature\": selected_features, \"Importance\": best_model.feature_importances_}\n",
    "    )\n",
    "    print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "estimators = [\n",
    "    (\"encoder\", TargetEncoder()),\n",
    "    (\"clf\", xgb.XGBClassifier(random_state=8)),\n",
    "]\n",
    "\n",
    "pipe = Pipeline(steps=estimators, verbose=True)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import Gr\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "\n",
    "searchSpace = {\n",
    "    \"clf__max_depth\": Integer(5, 11),\n",
    "    \"clf__learning_rate\": Real(0.001, 1.0, prior=\"log-uniform\"),\n",
    "    \"clf__subsample\": Real(0.5, 1.0),\n",
    "    \"clf__colsample_bytree\": Real(0.0, 0.5),\n",
    "    \"clf__colsample_bylevel\": Real(0.5, 1.0),\n",
    "    \"clf__colsample_bynode\": Real(0.0, 0.5),\n",
    "    \"clf__reg_alpha\": Real(0.0, 10.0),\n",
    "    \"clf__reg_lambda\": Real(0.0, 10.0),\n",
    "    \"clf__gamma\": Real(0.0, 10.0),\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    pipe, search_spaces=searchSpace, cv=3, n_iter=50, scoring=\"roc_auc\", random_state=7\n",
    ")\n",
    "\n",
    "opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_estimator_.steps"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
