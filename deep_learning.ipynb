{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "input"
    ]
   },
   "outputs": [],
   "source": [
    "splitPartCount = 5\n",
    "splitSeed = 27\n",
    "hoursPerWindow = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1213"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.class_patient import Patients\n",
    "\n",
    "\n",
    "patients = Patients.loadPatients()\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill measures whose null represent false value\n",
    "\n",
    "from constants import NULLABLE_MEASURES\n",
    "\n",
    "\n",
    "nullableMeasures = NULLABLE_MEASURES\n",
    "\n",
    "for measureName in nullableMeasures:\n",
    "    patients.fillMissingMeasureValue(measureName, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pco2 917\n",
      "ph 954\n",
      "po2 917\n",
      "albumin 406\n",
      "hba1c 326\n",
      "lymphocyte 446\n",
      "height 415\n",
      "urine-ketone 294\n",
      "crp 19\n"
     ]
    }
   ],
   "source": [
    "# remove measures with less than 80% of data\n",
    "\n",
    "measures = patients.getMeasures()\n",
    "\n",
    "for measure, count in measures.items():\n",
    "    if count < len(patients) * 80 / 100:\n",
    "        patients.removeMeasures([measure])\n",
    "        print(measure, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove patients with less than 80% of data\n",
    "\n",
    "patients.removePatientByMissingFeatures()\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitedPatients = patients.split(splitPartCount, splitSeed)\n",
    "\n",
    "len(splitedPatients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>akd</th>\n",
       "      <th>ag</th>\n",
       "      <th>age</th>\n",
       "      <th>bg</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bun</th>\n",
       "      <th>calcium</th>\n",
       "      <th>...</th>\n",
       "      <th>race</th>\n",
       "      <th>rr</th>\n",
       "      <th>saps2</th>\n",
       "      <th>sbp</th>\n",
       "      <th>scr</th>\n",
       "      <th>sofa</th>\n",
       "      <th>use_NaHCO3</th>\n",
       "      <th>uti</th>\n",
       "      <th>wbc</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19054290</td>\n",
       "      <td>20046699</td>\n",
       "      <td>30643955</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14866589</td>\n",
       "      <td>20066152</td>\n",
       "      <td>33060916</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14849360</td>\n",
       "      <td>20152551</td>\n",
       "      <td>32817197</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>UNABLE TO OBTAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16171124</td>\n",
       "      <td>20167052</td>\n",
       "      <td>38239449</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>HISPANIC/LATINO - DOMINICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16815664</td>\n",
       "      <td>20240670</td>\n",
       "      <td>37751533</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15517352</td>\n",
       "      <td>29801212</td>\n",
       "      <td>32814591</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10383045</td>\n",
       "      <td>29899941</td>\n",
       "      <td>39755932</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15679298</td>\n",
       "      <td>29905973</td>\n",
       "      <td>39834726</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10912213</td>\n",
       "      <td>29911812</td>\n",
       "      <td>34040470</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17657693</td>\n",
       "      <td>29997858</td>\n",
       "      <td>31578780</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id   hadm_id   stay_id    akd  ag  age  bg  bicarbonate  bun  \\\n",
       "0     19054290  20046699  30643955  False NaN   65 NaN          NaN  NaN   \n",
       "0     14866589  20066152  33060916  False NaN   37 NaN          NaN  NaN   \n",
       "0     14849360  20152551  32817197  False NaN   59 NaN          NaN  NaN   \n",
       "0     16171124  20167052  38239449  False NaN   37 NaN          NaN  NaN   \n",
       "0     16815664  20240670  37751533  False NaN   42 NaN          NaN  NaN   \n",
       "..         ...       ...       ...    ...  ..  ...  ..          ...  ...   \n",
       "0     15517352  29801212  32814591  False NaN   20 NaN          NaN  NaN   \n",
       "0     10383045  29899941  39755932  False NaN   58 NaN          NaN  NaN   \n",
       "0     15679298  29905973  39834726  False NaN   50 NaN          NaN  NaN   \n",
       "0     10912213  29911812  34040470  False NaN   47 NaN          NaN  NaN   \n",
       "0     17657693  29997858  31578780  False NaN   34 NaN          NaN  NaN   \n",
       "\n",
       "    calcium  ...                         race  rr  saps2  sbp  scr  sofa  \\\n",
       "0       NaN  ...                        WHITE NaN     34  NaN  NaN     3   \n",
       "0       NaN  ...                        WHITE NaN     22  NaN  NaN     2   \n",
       "0       NaN  ...             UNABLE TO OBTAIN NaN     31  NaN  NaN     7   \n",
       "0       NaN  ...  HISPANIC/LATINO - DOMINICAN NaN     15  NaN  NaN     2   \n",
       "0       NaN  ...       BLACK/AFRICAN AMERICAN NaN     27  NaN  NaN     2   \n",
       "..      ...  ...                          ...  ..    ...  ...  ...   ...   \n",
       "0       NaN  ...                        WHITE NaN     30  NaN  NaN     4   \n",
       "0       NaN  ...                        WHITE NaN     23  NaN  NaN     1   \n",
       "0       NaN  ...                        WHITE NaN     32  NaN  NaN     3   \n",
       "0       NaN  ...                        WHITE NaN     23  NaN  NaN     2   \n",
       "0       NaN  ...                        OTHER NaN     19  NaN  NaN     1   \n",
       "\n",
       "    use_NaHCO3  uti wbc  weight  \n",
       "0          0.0    0 NaN   74.50  \n",
       "0          0.0    0 NaN     NaN  \n",
       "0          0.0    0 NaN     NaN  \n",
       "0          0.0    0 NaN     NaN  \n",
       "0          NaN    0 NaN   43.00  \n",
       "..         ...  ...  ..     ...  \n",
       "0          NaN    0 NaN     NaN  \n",
       "0          0.0    0 NaN   59.40  \n",
       "0          0.0    0 NaN   47.40  \n",
       "0          0.0    0 NaN   89.05  \n",
       "0          0.0    0 NaN     NaN  \n",
       "\n",
       "[242 rows x 43 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Timedelta\n",
    "\n",
    "\n",
    "splitedPatients[0].getMeasuresBetween(Timedelta(-6), Timedelta(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitedPatients = patients.split(splitPartCount, splitSeed)\n",
    "\n",
    "\n",
    "def trainTest():\n",
    "    for i in range(splitedPatients.__len__()):\n",
    "        testPatients = splitedPatients[i]\n",
    "\n",
    "        trainPatientsList = splitedPatients[:i] + splitedPatients[i + 1 :]\n",
    "        trainPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatientsList:\n",
    "            trainPatients += trainPatientsElem\n",
    "\n",
    "        yield trainPatients, testPatients\n",
    "\n",
    "\n",
    "def trainValTest():\n",
    "    for i in range(splitedPatients.__len__()):\n",
    "        testPatients = splitedPatients[i]\n",
    "\n",
    "        trainPatientsList = splitedPatients[:i] + splitedPatients[i + 1 :]\n",
    "        trainPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatientsList:\n",
    "            trainPatients += trainPatientsElem\n",
    "\n",
    "        *trainPatients, valPatients = trainPatients.split(5, 27)\n",
    "        tmpPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatients:\n",
    "            tmpPatients += trainPatientsElem\n",
    "        trainPatients = tmpPatients\n",
    "\n",
    "        yield trainPatients, valPatients, testPatients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967 242\n",
      "967 242\n",
      "967 242\n",
      "967 242\n",
      "968 241\n"
     ]
    }
   ],
   "source": [
    "for trainPatients, testPatients in trainTest():\n",
    "    print(len(trainPatients.patientList), len(testPatients.patientList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0 created\n",
      "Dataset 1 created\n",
      "Dataset 2 created\n",
      "Dataset 3 created\n",
      "Dataset 4 created\n"
     ]
    }
   ],
   "source": [
    "from constants import CATEGORICAL_MEASURES, TEMP_PATH\n",
    "from utils.prepare_data import patientsToNumpy\n",
    "\n",
    "\n",
    "dataset = []\n",
    "for i, (trainPatients, testPatients) in enumerate(trainTest()):\n",
    "    # trainPatients.fillMissingMeasureValue(CATEGORICAL_MEASURES, 0)\n",
    "    npTrainX, categoryEncoder, numericEncoder, oulier, columns = patientsToNumpy(\n",
    "        trainPatients, hoursPerWindow, CATEGORICAL_MEASURES\n",
    "    )\n",
    "\n",
    "    # testPatients.fillMissingMeasureValue(CATEGORICAL_MEASURES, 0)\n",
    "    npTestX, *_ = patientsToNumpy(\n",
    "        testPatients,\n",
    "        hoursPerWindow,\n",
    "        CATEGORICAL_MEASURES,\n",
    "        columns,\n",
    "        categoryEncoder,\n",
    "        numericEncoder,\n",
    "        oulier,\n",
    "    )\n",
    "    trainY = [p.akdPositive for p in trainPatients]\n",
    "    testY = [p.akdPositive for p in testPatients]\n",
    "\n",
    "    dataset.append((npTrainX, trainY, npTestX, testY))\n",
    "\n",
    "    print(f\"Dataset {i} created\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41441534"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "(TEMP_PATH / f\"train-test-set-{splitPartCount}-{splitSeed}-{hoursPerWindow}.pkl\").write_bytes(\n",
    "    pickle.dumps(dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0 created\n",
      "Dataset 1 created\n",
      "Dataset 2 created\n",
      "Dataset 3 created\n",
      "Dataset 4 created\n"
     ]
    }
   ],
   "source": [
    "from constants import CATEGORICAL_MEASURES, TEMP_PATH\n",
    "from utils.prepare_data import patientsToNumpy\n",
    "\n",
    "\n",
    "datavalset = []\n",
    "for i, (trainPatients, valPatients, testPatients) in enumerate(trainValTest()):\n",
    "    # trainPatients.fillMissingMeasureValue(CATEGORICAL_MEASURES, 0)\n",
    "    npTrainX, categoryEncoder, numericEncoder, oulier, columns = patientsToNumpy(\n",
    "        trainPatients, hoursPerWindow, CATEGORICAL_MEASURES\n",
    "    )\n",
    "\n",
    "    # testPatients.fillMissingMeasureValue(CATEGORICAL_MEASURES, 0)\n",
    "    npTestX, *_ = patientsToNumpy(\n",
    "        testPatients,\n",
    "        hoursPerWindow,\n",
    "        CATEGORICAL_MEASURES,\n",
    "        columns,\n",
    "        categoryEncoder,\n",
    "        numericEncoder,\n",
    "        oulier,\n",
    "    )\n",
    "\n",
    "    npValX, *_ = patientsToNumpy(\n",
    "        valPatients,\n",
    "        hoursPerWindow,\n",
    "        CATEGORICAL_MEASURES,\n",
    "        columns,\n",
    "        categoryEncoder,\n",
    "        numericEncoder,\n",
    "        oulier,\n",
    "    )\n",
    "\n",
    "    trainY = [p.akdPositive for p in trainPatients]\n",
    "    testY = [p.akdPositive for p in testPatients]\n",
    "    valY = [p.akdPositive for p in valPatients]\n",
    "\n",
    "    datavalset.append((npTrainX, trainY, npValX, valY, npTestX, testY))\n",
    "\n",
    "    print(f\"Dataset {i} created\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40861464"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "(TEMP_PATH / f\"train-val-test-set-{splitPartCount}-{splitSeed}-{hoursPerWindow}.pkl\").write_bytes(\n",
    "    pickle.dumps(datavalset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from constants import TEMP_PATH\n",
    "\n",
    "# load if not exist dataset\n",
    "if \"dataset\" not in locals():\n",
    "    dataset = pickle.loads(\n",
    "        (TEMP_PATH / f\"dataset-{splitPartCount}-{splitSeed}-{hoursPerWindow}.pkl\").read_bytes()\n",
    "    )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def createModel(timeSteps, features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(timeSteps, features), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"AUC\", \"accuracy\", \"precision\", \"recall\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 23:34:21.396009: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-06 23:34:21.411522: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/tu/codepy/hust.year2023.PredictingRiskDiabeticKetoacidosis-associatedKidneyInjury/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.6890 - accuracy: 0.6496 - loss: 0.6459 - precision: 0.5193 - recall: 0.6205 - val_AUC: 0.7377 - val_accuracy: 0.7010 - val_loss: 0.6261 - val_precision: 0.5882 - val_recall: 0.6849\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.7681 - accuracy: 0.7341 - loss: 0.5813 - precision: 0.6412 - recall: 0.7308 - val_AUC: 0.7502 - val_accuracy: 0.7062 - val_loss: 0.6010 - val_precision: 0.5952 - val_recall: 0.6849\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8011 - accuracy: 0.7255 - loss: 0.5484 - precision: 0.6442 - recall: 0.7338 - val_AUC: 0.7517 - val_accuracy: 0.6856 - val_loss: 0.5873 - val_precision: 0.5769 - val_recall: 0.6164\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8368 - accuracy: 0.7740 - loss: 0.5012 - precision: 0.6571 - recall: 0.7909 - val_AUC: 0.7496 - val_accuracy: 0.6804 - val_loss: 0.6161 - val_precision: 0.5679 - val_recall: 0.6301\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8464 - accuracy: 0.7938 - loss: 0.4912 - precision: 0.7247 - recall: 0.8150 - val_AUC: 0.7460 - val_accuracy: 0.6753 - val_loss: 0.6066 - val_precision: 0.5625 - val_recall: 0.6164\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8489 - accuracy: 0.7866 - loss: 0.4813 - precision: 0.7101 - recall: 0.7791 - val_AUC: 0.7411 - val_accuracy: 0.6753 - val_loss: 0.6209 - val_precision: 0.5641 - val_recall: 0.6027\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8919 - accuracy: 0.8313 - loss: 0.4210 - precision: 0.7747 - recall: 0.8214 - val_AUC: 0.7365 - val_accuracy: 0.6701 - val_loss: 0.6457 - val_precision: 0.5570 - val_recall: 0.6027\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8865 - accuracy: 0.8375 - loss: 0.4192 - precision: 0.7711 - recall: 0.8201 - val_AUC: 0.7165 - val_accuracy: 0.6598 - val_loss: 0.6870 - val_precision: 0.5432 - val_recall: 0.6027\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9159 - accuracy: 0.8545 - loss: 0.3641 - precision: 0.8053 - recall: 0.8620 - val_AUC: 0.7150 - val_accuracy: 0.6804 - val_loss: 0.6790 - val_precision: 0.5821 - val_recall: 0.5342\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9122 - accuracy: 0.8734 - loss: 0.3672 - precision: 0.8647 - recall: 0.8223 - val_AUC: 0.7190 - val_accuracy: 0.6753 - val_loss: 0.7585 - val_precision: 0.5714 - val_recall: 0.5479\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9365 - accuracy: 0.8893 - loss: 0.3117 - precision: 0.8943 - recall: 0.8334 - val_AUC: 0.7058 - val_accuracy: 0.6598 - val_loss: 0.8426 - val_precision: 0.5467 - val_recall: 0.5616\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9208 - accuracy: 0.8884 - loss: 0.3277 - precision: 0.8804 - recall: 0.8500 - val_AUC: 0.7111 - val_accuracy: 0.6753 - val_loss: 0.7973 - val_precision: 0.5806 - val_recall: 0.4932\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9489 - accuracy: 0.9039 - loss: 0.2744 - precision: 0.9162 - recall: 0.8392 - val_AUC: 0.6923 - val_accuracy: 0.6546 - val_loss: 0.8542 - val_precision: 0.5517 - val_recall: 0.4384\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7726 - accuracy: 0.7235 - loss: 0.5744 - precision: 0.6573 - recall: 0.7242 \n",
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.6526 - accuracy: 0.5589 - loss: 0.6675 - precision: 0.4750 - recall: 0.7972 - val_AUC: 0.7574 - val_accuracy: 0.7216 - val_loss: 0.6015 - val_precision: 0.6067 - val_recall: 0.7397\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.7980 - accuracy: 0.7289 - loss: 0.5576 - precision: 0.6140 - recall: 0.7604 - val_AUC: 0.7671 - val_accuracy: 0.7113 - val_loss: 0.5825 - val_precision: 0.6024 - val_recall: 0.6849\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8162 - accuracy: 0.7513 - loss: 0.5261 - precision: 0.6853 - recall: 0.7335 - val_AUC: 0.7680 - val_accuracy: 0.7371 - val_loss: 0.5700 - val_precision: 0.6447 - val_recall: 0.6712\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8247 - accuracy: 0.7813 - loss: 0.5103 - precision: 0.7113 - recall: 0.7657 - val_AUC: 0.7593 - val_accuracy: 0.7268 - val_loss: 0.5841 - val_precision: 0.6351 - val_recall: 0.6438\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8554 - accuracy: 0.7766 - loss: 0.4803 - precision: 0.7188 - recall: 0.8077 - val_AUC: 0.7480 - val_accuracy: 0.7268 - val_loss: 0.6129 - val_precision: 0.6282 - val_recall: 0.6712\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8659 - accuracy: 0.8225 - loss: 0.4597 - precision: 0.7758 - recall: 0.7847 - val_AUC: 0.7478 - val_accuracy: 0.7371 - val_loss: 0.6317 - val_precision: 0.6486 - val_recall: 0.6575\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8874 - accuracy: 0.8418 - loss: 0.4219 - precision: 0.8051 - recall: 0.8084 - val_AUC: 0.7466 - val_accuracy: 0.7268 - val_loss: 0.6520 - val_precision: 0.6282 - val_recall: 0.6712\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9129 - accuracy: 0.8547 - loss: 0.3719 - precision: 0.8079 - recall: 0.8244 - val_AUC: 0.7257 - val_accuracy: 0.7113 - val_loss: 0.6470 - val_precision: 0.6164 - val_recall: 0.6164\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9316 - accuracy: 0.8612 - loss: 0.3475 - precision: 0.8166 - recall: 0.8418 - val_AUC: 0.7402 - val_accuracy: 0.7010 - val_loss: 0.7687 - val_precision: 0.6000 - val_recall: 0.6164\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9389 - accuracy: 0.8780 - loss: 0.3071 - precision: 0.8437 - recall: 0.8519 - val_AUC: 0.7103 - val_accuracy: 0.6649 - val_loss: 0.8404 - val_precision: 0.5571 - val_recall: 0.5342\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9508 - accuracy: 0.9116 - loss: 0.2700 - precision: 0.8973 - recall: 0.8897 - val_AUC: 0.7015 - val_accuracy: 0.6598 - val_loss: 0.9516 - val_precision: 0.5455 - val_recall: 0.5753\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9517 - accuracy: 0.9217 - loss: 0.2589 - precision: 0.9025 - recall: 0.9095 - val_AUC: 0.6975 - val_accuracy: 0.6495 - val_loss: 0.9905 - val_precision: 0.5325 - val_recall: 0.5616\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9512 - accuracy: 0.9079 - loss: 0.2587 - precision: 0.8669 - recall: 0.9111 - val_AUC: 0.6869 - val_accuracy: 0.6392 - val_loss: 1.0438 - val_precision: 0.5211 - val_recall: 0.5068\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8204 - accuracy: 0.7760 - loss: 0.5308 - precision: 0.6941 - recall: 0.8220 \n",
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.6417 - accuracy: 0.6047 - loss: 0.6740 - precision: 0.5217 - recall: 0.7488 - val_AUC: 0.7525 - val_accuracy: 0.7062 - val_loss: 0.5988 - val_precision: 0.5976 - val_recall: 0.6712\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8021 - accuracy: 0.7427 - loss: 0.5588 - precision: 0.6262 - recall: 0.7466 - val_AUC: 0.7490 - val_accuracy: 0.7010 - val_loss: 0.5890 - val_precision: 0.5926 - val_recall: 0.6575\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.8122 - accuracy: 0.7625 - loss: 0.5269 - precision: 0.6632 - recall: 0.7886 - val_AUC: 0.7381 - val_accuracy: 0.6804 - val_loss: 0.6064 - val_precision: 0.5696 - val_recall: 0.6164\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8209 - accuracy: 0.7726 - loss: 0.5192 - precision: 0.6766 - recall: 0.7886 - val_AUC: 0.7197 - val_accuracy: 0.6649 - val_loss: 0.6383 - val_precision: 0.5513 - val_recall: 0.5890\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8393 - accuracy: 0.7784 - loss: 0.5004 - precision: 0.6724 - recall: 0.8259 - val_AUC: 0.7239 - val_accuracy: 0.6907 - val_loss: 0.6424 - val_precision: 0.5823 - val_recall: 0.6301\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8727 - accuracy: 0.7904 - loss: 0.4547 - precision: 0.6938 - recall: 0.8361 - val_AUC: 0.7148 - val_accuracy: 0.6804 - val_loss: 0.6659 - val_precision: 0.5632 - val_recall: 0.6712\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8890 - accuracy: 0.8220 - loss: 0.4286 - precision: 0.7410 - recall: 0.8752 - val_AUC: 0.7067 - val_accuracy: 0.6598 - val_loss: 0.6728 - val_precision: 0.5455 - val_recall: 0.5753\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8833 - accuracy: 0.8087 - loss: 0.4323 - precision: 0.7175 - recall: 0.8322 - val_AUC: 0.7000 - val_accuracy: 0.6701 - val_loss: 0.6947 - val_precision: 0.5634 - val_recall: 0.5479\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9158 - accuracy: 0.8570 - loss: 0.3716 - precision: 0.7951 - recall: 0.8487 - val_AUC: 0.6939 - val_accuracy: 0.6753 - val_loss: 0.7528 - val_precision: 0.5658 - val_recall: 0.5890\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9261 - accuracy: 0.8513 - loss: 0.3467 - precision: 0.7984 - recall: 0.8494 - val_AUC: 0.6580 - val_accuracy: 0.6546 - val_loss: 0.8073 - val_precision: 0.5455 - val_recall: 0.4932\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9485 - accuracy: 0.8911 - loss: 0.2949 - precision: 0.8219 - recall: 0.9042 - val_AUC: 0.6752 - val_accuracy: 0.6546 - val_loss: 0.8509 - val_precision: 0.5417 - val_recall: 0.5342\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9511 - accuracy: 0.9000 - loss: 0.2817 - precision: 0.8389 - recall: 0.9297 - val_AUC: 0.6362 - val_accuracy: 0.6237 - val_loss: 0.9342 - val_precision: 0.5000 - val_recall: 0.4247\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8553 - accuracy: 0.8144 - loss: 0.4808 - precision: 0.7459 - recall: 0.8061 \n",
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.6724 - accuracy: 0.6166 - loss: 0.6510 - precision: 0.5020 - recall: 0.6658 - val_AUC: 0.7562 - val_accuracy: 0.7113 - val_loss: 0.6292 - val_precision: 0.5977 - val_recall: 0.7123\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8252 - accuracy: 0.7757 - loss: 0.5327 - precision: 0.6791 - recall: 0.7881 - val_AUC: 0.7556 - val_accuracy: 0.7165 - val_loss: 0.6042 - val_precision: 0.6125 - val_recall: 0.6712\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8265 - accuracy: 0.7602 - loss: 0.5107 - precision: 0.6731 - recall: 0.7644 - val_AUC: 0.7453 - val_accuracy: 0.7268 - val_loss: 0.6231 - val_precision: 0.6282 - val_recall: 0.6712\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8435 - accuracy: 0.8121 - loss: 0.4855 - precision: 0.7459 - recall: 0.7823 - val_AUC: 0.7380 - val_accuracy: 0.7010 - val_loss: 0.6558 - val_precision: 0.5974 - val_recall: 0.6301\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8544 - accuracy: 0.7924 - loss: 0.4640 - precision: 0.7180 - recall: 0.7616 - val_AUC: 0.7241 - val_accuracy: 0.7062 - val_loss: 0.6843 - val_precision: 0.6111 - val_recall: 0.6027\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8686 - accuracy: 0.8197 - loss: 0.4604 - precision: 0.7868 - recall: 0.7842 - val_AUC: 0.7190 - val_accuracy: 0.7062 - val_loss: 0.7079 - val_precision: 0.6143 - val_recall: 0.5890\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8919 - accuracy: 0.8364 - loss: 0.4223 - precision: 0.8312 - recall: 0.7663 - val_AUC: 0.7136 - val_accuracy: 0.7165 - val_loss: 0.7525 - val_precision: 0.6216 - val_recall: 0.6301\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9317 - accuracy: 0.8800 - loss: 0.3371 - precision: 0.8343 - recall: 0.8330 - val_AUC: 0.7070 - val_accuracy: 0.7113 - val_loss: 0.8271 - val_precision: 0.6133 - val_recall: 0.6301\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9326 - accuracy: 0.8605 - loss: 0.3400 - precision: 0.8079 - recall: 0.8432 - val_AUC: 0.6779 - val_accuracy: 0.7010 - val_loss: 0.8077 - val_precision: 0.6119 - val_recall: 0.5616\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9287 - accuracy: 0.8602 - loss: 0.3399 - precision: 0.8344 - recall: 0.8155 - val_AUC: 0.6786 - val_accuracy: 0.6443 - val_loss: 0.8804 - val_precision: 0.5256 - val_recall: 0.5616\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9617 - accuracy: 0.9131 - loss: 0.2577 - precision: 0.8926 - recall: 0.8897 - val_AUC: 0.6732 - val_accuracy: 0.6495 - val_loss: 0.9253 - val_precision: 0.5333 - val_recall: 0.5479\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9600 - accuracy: 0.9188 - loss: 0.2548 - precision: 0.9137 - recall: 0.8728 - val_AUC: 0.6779 - val_accuracy: 0.6546 - val_loss: 0.9788 - val_precision: 0.5429 - val_recall: 0.5205\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7632 - accuracy: 0.7016 - loss: 0.5916 - precision: 0.6349 - recall: 0.6547 \n",
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.6405 - accuracy: 0.5738 - loss: 0.6657 - precision: 0.4830 - recall: 0.6947 - val_AUC: 0.7617 - val_accuracy: 0.6907 - val_loss: 0.5996 - val_precision: 0.5926 - val_recall: 0.6400\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.7902 - accuracy: 0.7279 - loss: 0.5610 - precision: 0.6274 - recall: 0.7349 - val_AUC: 0.7600 - val_accuracy: 0.7010 - val_loss: 0.5847 - val_precision: 0.6049 - val_recall: 0.6533\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8031 - accuracy: 0.7545 - loss: 0.5386 - precision: 0.6730 - recall: 0.7441 - val_AUC: 0.7643 - val_accuracy: 0.7062 - val_loss: 0.5879 - val_precision: 0.6071 - val_recall: 0.6800\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.8553 - accuracy: 0.7953 - loss: 0.4780 - precision: 0.7418 - recall: 0.7690 - val_AUC: 0.7511 - val_accuracy: 0.7113 - val_loss: 0.5878 - val_precision: 0.6203 - val_recall: 0.6533\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8558 - accuracy: 0.7769 - loss: 0.4830 - precision: 0.7165 - recall: 0.7670 - val_AUC: 0.7565 - val_accuracy: 0.7165 - val_loss: 0.5966 - val_precision: 0.6220 - val_recall: 0.6800\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8674 - accuracy: 0.8084 - loss: 0.4533 - precision: 0.7244 - recall: 0.8028 - val_AUC: 0.7477 - val_accuracy: 0.7062 - val_loss: 0.6156 - val_precision: 0.6216 - val_recall: 0.6133\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9052 - accuracy: 0.8339 - loss: 0.3986 - precision: 0.7611 - recall: 0.8365 - val_AUC: 0.7483 - val_accuracy: 0.7062 - val_loss: 0.6305 - val_precision: 0.6250 - val_recall: 0.6000\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9067 - accuracy: 0.8362 - loss: 0.4003 - precision: 0.7721 - recall: 0.8350 - val_AUC: 0.7422 - val_accuracy: 0.7113 - val_loss: 0.6628 - val_precision: 0.6234 - val_recall: 0.6400\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9140 - accuracy: 0.8627 - loss: 0.3692 - precision: 0.8247 - recall: 0.8260 - val_AUC: 0.7272 - val_accuracy: 0.6907 - val_loss: 0.6775 - val_precision: 0.6087 - val_recall: 0.5600\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9138 - accuracy: 0.8453 - loss: 0.3792 - precision: 0.7926 - recall: 0.8407 - val_AUC: 0.7426 - val_accuracy: 0.7113 - val_loss: 0.7187 - val_precision: 0.6377 - val_recall: 0.5867\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9335 - accuracy: 0.8741 - loss: 0.3304 - precision: 0.8547 - recall: 0.8358 - val_AUC: 0.7164 - val_accuracy: 0.6804 - val_loss: 0.7327 - val_precision: 0.5942 - val_recall: 0.5467\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9444 - accuracy: 0.8795 - loss: 0.3003 - precision: 0.8075 - recall: 0.8939 - val_AUC: 0.6863 - val_accuracy: 0.6753 - val_loss: 0.8013 - val_precision: 0.5882 - val_recall: 0.5333\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7863 - accuracy: 0.7175 - loss: 0.5606 - precision: 0.6353 - recall: 0.7200 \n",
      "Loses: [0.570824384689331, 0.5590643286705017, 0.49564671516418457, 0.5870479941368103, 0.5782794952392578] 0.5581725835800171 0.032583507279192396\n",
      "AUCs: [0.7643036246299744, 0.7967418432235718, 0.8426064848899841, 0.7646975517272949, 0.7751983404159546] 0.788709568977356 0.02940807835817389\n",
      "Accuracies: [0.7355371713638306, 0.7520661354064941, 0.8016529083251953, 0.702479362487793, 0.7012448310852051] 0.7385960817337036 0.0370580517363855\n",
      "Precisions: [0.6476190686225891, 0.6521739363670349, 0.7326732873916626, 0.6224489808082581, 0.6074766516685486] 0.6524783849716187 0.04331708469687279\n",
      "Recals: [0.7157894968986511, 0.7894737124443054, 0.7789473533630371, 0.6354166865348816, 0.6842105388641357] 0.7207675576210022 0.05788158990092358\n"
     ]
    }
   ],
   "source": [
    "# crossfold\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "loses = []\n",
    "aucs = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recals = []\n",
    "for i, (npTrainX, trainY, npTestX, testY) in enumerate(dataset):\n",
    "    npTrainX = np.nan_to_num(npTrainX, nan=0)\n",
    "    npTestX = np.nan_to_num(npTestX, nan=0)\n",
    "\n",
    "    model = createModel(npTrainX.shape[1], npTrainX.shape[2])\n",
    "\n",
    "    neg, pos = np.bincount(trainY)\n",
    "    weight0 = (1 / neg) * (len(trainY)) / 2.0\n",
    "    weight1 = (1 / pos) * (len(trainY)) / 2.0\n",
    "    weight = {0: weight0, 1: weight1}\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    trainY = np.array(trainY)\n",
    "    model.fit(\n",
    "        npTrainX,\n",
    "        trainY,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        class_weight=weight,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    testY = np.array(testY)\n",
    "    loss, auc, accuracy, precison, recal = model.evaluate(npTestX, testY)\n",
    "    loses.append(loss)\n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precison)\n",
    "    recals.append(recal)\n",
    "\n",
    "    pass\n",
    "\n",
    "print(\"Loses:\", loses, np.mean(loses), np.std(loses))\n",
    "print(\"AUCs:\", aucs, np.mean(aucs), np.std(aucs))\n",
    "print(\"Accuracies:\", accuracies, np.mean(accuracies), np.std(accuracies))\n",
    "print(\"Precisions:\", precisions, np.mean(precisions), np.std(precisions))\n",
    "print(\"Recals:\", recals, np.mean(recals), np.std(recals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def createModel(timeSteps, features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(timeSteps, features), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"AUC\", \"accuracy\", \"precision\", \"recall\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.5657 - accuracy: 0.5604 - loss: 0.6889 - precision: 0.4332 - recall: 0.3177 - val_AUC: 0.7348 - val_accuracy: 0.6736 - val_loss: 0.5963 - val_precision: 0.5844 - val_recall: 0.5921\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.7931 - accuracy: 0.7341 - loss: 0.5698 - precision: 0.6421 - recall: 0.7410 - val_AUC: 0.7294 - val_accuracy: 0.6736 - val_loss: 0.6125 - val_precision: 0.5765 - val_recall: 0.6447\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8137 - accuracy: 0.7500 - loss: 0.5279 - precision: 0.6505 - recall: 0.7925 - val_AUC: 0.7290 - val_accuracy: 0.6839 - val_loss: 0.6329 - val_precision: 0.5904 - val_recall: 0.6447\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8157 - accuracy: 0.7640 - loss: 0.5260 - precision: 0.6751 - recall: 0.7715 - val_AUC: 0.7191 - val_accuracy: 0.6477 - val_loss: 0.6392 - val_precision: 0.5476 - val_recall: 0.6053\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8417 - accuracy: 0.7870 - loss: 0.4884 - precision: 0.7079 - recall: 0.7890 - val_AUC: 0.7179 - val_accuracy: 0.6425 - val_loss: 0.6779 - val_precision: 0.5422 - val_recall: 0.5921\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8723 - accuracy: 0.8279 - loss: 0.4463 - precision: 0.7408 - recall: 0.8575 - val_AUC: 0.7145 - val_accuracy: 0.6528 - val_loss: 0.6726 - val_precision: 0.5529 - val_recall: 0.6184\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8751 - accuracy: 0.8320 - loss: 0.4398 - precision: 0.7584 - recall: 0.8230 - val_AUC: 0.7141 - val_accuracy: 0.6528 - val_loss: 0.7047 - val_precision: 0.5529 - val_recall: 0.6184\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8783 - accuracy: 0.8242 - loss: 0.4359 - precision: 0.7584 - recall: 0.8464 - val_AUC: 0.6985 - val_accuracy: 0.6788 - val_loss: 0.7073 - val_precision: 0.5897 - val_recall: 0.6053\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9151 - accuracy: 0.8553 - loss: 0.3738 - precision: 0.8134 - recall: 0.8445 - val_AUC: 0.6842 - val_accuracy: 0.6528 - val_loss: 0.7694 - val_precision: 0.5570 - val_recall: 0.5789\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9169 - accuracy: 0.8514 - loss: 0.3681 - precision: 0.7904 - recall: 0.8589 - val_AUC: 0.6628 - val_accuracy: 0.6684 - val_loss: 0.7666 - val_precision: 0.5811 - val_recall: 0.5658\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9186 - accuracy: 0.8742 - loss: 0.3496 - precision: 0.8244 - recall: 0.8269 - val_AUC: 0.6789 - val_accuracy: 0.6528 - val_loss: 0.8483 - val_precision: 0.5584 - val_recall: 0.5658\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7864 - accuracy: 0.7239 - loss: 0.5838 - precision: 0.6651 - recall: 0.6937 \n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.6593 - accuracy: 0.5455 - loss: 0.6579 - precision: 0.4555 - recall: 0.7420 - val_AUC: 0.7359 - val_accuracy: 0.6943 - val_loss: 0.6126 - val_precision: 0.6000 - val_recall: 0.6711\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8208 - accuracy: 0.7387 - loss: 0.5457 - precision: 0.6435 - recall: 0.7785 - val_AUC: 0.7407 - val_accuracy: 0.7098 - val_loss: 0.5881 - val_precision: 0.6351 - val_recall: 0.6184\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.8310 - accuracy: 0.7540 - loss: 0.5153 - precision: 0.6890 - recall: 0.7315 - val_AUC: 0.7433 - val_accuracy: 0.7047 - val_loss: 0.5857 - val_precision: 0.6508 - val_recall: 0.5395\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8230 - accuracy: 0.7702 - loss: 0.5228 - precision: 0.7265 - recall: 0.7017 - val_AUC: 0.7424 - val_accuracy: 0.7047 - val_loss: 0.5914 - val_precision: 0.6377 - val_recall: 0.5789\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8498 - accuracy: 0.7921 - loss: 0.4826 - precision: 0.7501 - recall: 0.7266 - val_AUC: 0.7474 - val_accuracy: 0.7047 - val_loss: 0.5878 - val_precision: 0.6610 - val_recall: 0.5132\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8290 - accuracy: 0.7730 - loss: 0.5112 - precision: 0.7151 - recall: 0.7343 - val_AUC: 0.7428 - val_accuracy: 0.7047 - val_loss: 0.6087 - val_precision: 0.6462 - val_recall: 0.5526\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8890 - accuracy: 0.8253 - loss: 0.4195 - precision: 0.7660 - recall: 0.7886 - val_AUC: 0.7239 - val_accuracy: 0.6891 - val_loss: 0.6277 - val_precision: 0.6333 - val_recall: 0.5000\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8960 - accuracy: 0.8372 - loss: 0.4152 - precision: 0.7519 - recall: 0.8454 - val_AUC: 0.7207 - val_accuracy: 0.6995 - val_loss: 0.6670 - val_precision: 0.6364 - val_recall: 0.5526\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8910 - accuracy: 0.8330 - loss: 0.4090 - precision: 0.7706 - recall: 0.7936 - val_AUC: 0.7059 - val_accuracy: 0.6528 - val_loss: 0.6705 - val_precision: 0.5882 - val_recall: 0.3947\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9294 - accuracy: 0.8586 - loss: 0.3547 - precision: 0.8180 - recall: 0.8234 - val_AUC: 0.6992 - val_accuracy: 0.6736 - val_loss: 0.7279 - val_precision: 0.6000 - val_recall: 0.5132\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9469 - accuracy: 0.8883 - loss: 0.3038 - precision: 0.8358 - recall: 0.8884 - val_AUC: 0.6858 - val_accuracy: 0.6632 - val_loss: 0.7721 - val_precision: 0.5873 - val_recall: 0.4868\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9561 - accuracy: 0.9016 - loss: 0.2761 - precision: 0.8579 - recall: 0.9019 - val_AUC: 0.6799 - val_accuracy: 0.6580 - val_loss: 0.8515 - val_precision: 0.5926 - val_recall: 0.4211\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9555 - accuracy: 0.8993 - loss: 0.2665 - precision: 0.8344 - recall: 0.8949 - val_AUC: 0.6576 - val_accuracy: 0.6477 - val_loss: 0.9925 - val_precision: 0.5714 - val_recall: 0.4211\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8013 - accuracy: 0.7571 - loss: 0.5465 - precision: 0.7565 - recall: 0.6260 \n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - AUC: 0.5620 - accuracy: 0.5995 - loss: 0.6959 - precision: 0.5093 - recall: 0.2283 - val_AUC: 0.7667 - val_accuracy: 0.7409 - val_loss: 0.5845 - val_precision: 0.6857 - val_recall: 0.6316\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.7450 - accuracy: 0.7038 - loss: 0.6090 - precision: 0.5964 - recall: 0.6387 - val_AUC: 0.7685 - val_accuracy: 0.7150 - val_loss: 0.5596 - val_precision: 0.6296 - val_recall: 0.6711\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.7983 - accuracy: 0.7436 - loss: 0.5557 - precision: 0.6584 - recall: 0.7627 - val_AUC: 0.7725 - val_accuracy: 0.7150 - val_loss: 0.5626 - val_precision: 0.6235 - val_recall: 0.6974\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8159 - accuracy: 0.7464 - loss: 0.5299 - precision: 0.6522 - recall: 0.7897 - val_AUC: 0.7716 - val_accuracy: 0.7150 - val_loss: 0.5594 - val_precision: 0.6296 - val_recall: 0.6711\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8401 - accuracy: 0.7669 - loss: 0.5033 - precision: 0.6700 - recall: 0.8353 - val_AUC: 0.7634 - val_accuracy: 0.7202 - val_loss: 0.5643 - val_precision: 0.6447 - val_recall: 0.6447\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8525 - accuracy: 0.7844 - loss: 0.4843 - precision: 0.7199 - recall: 0.7696 - val_AUC: 0.7574 - val_accuracy: 0.7047 - val_loss: 0.5774 - val_precision: 0.6377 - val_recall: 0.5789\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8675 - accuracy: 0.8019 - loss: 0.4787 - precision: 0.7232 - recall: 0.8087 - val_AUC: 0.7568 - val_accuracy: 0.7202 - val_loss: 0.6016 - val_precision: 0.6375 - val_recall: 0.6711\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8782 - accuracy: 0.8124 - loss: 0.4368 - precision: 0.7069 - recall: 0.8621 - val_AUC: 0.7403 - val_accuracy: 0.6943 - val_loss: 0.6213 - val_precision: 0.6164 - val_recall: 0.5921\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8975 - accuracy: 0.8216 - loss: 0.4167 - precision: 0.7395 - recall: 0.8618 - val_AUC: 0.7038 - val_accuracy: 0.6995 - val_loss: 0.6771 - val_precision: 0.6324 - val_recall: 0.5658\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9057 - accuracy: 0.8419 - loss: 0.3955 - precision: 0.7550 - recall: 0.8652 - val_AUC: 0.7083 - val_accuracy: 0.6995 - val_loss: 0.7331 - val_precision: 0.6324 - val_recall: 0.5658\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9364 - accuracy: 0.8766 - loss: 0.3163 - precision: 0.8146 - recall: 0.9010 - val_AUC: 0.7095 - val_accuracy: 0.6839 - val_loss: 0.8108 - val_precision: 0.6056 - val_recall: 0.5658\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9479 - accuracy: 0.8913 - loss: 0.2911 - precision: 0.8202 - recall: 0.9290 - val_AUC: 0.6632 - val_accuracy: 0.6839 - val_loss: 0.8438 - val_precision: 0.6190 - val_recall: 0.5132\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9560 - accuracy: 0.8823 - loss: 0.2781 - precision: 0.8173 - recall: 0.8965 - val_AUC: 0.6703 - val_accuracy: 0.6684 - val_loss: 0.8481 - val_precision: 0.5938 - val_recall: 0.5000\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9570 - accuracy: 0.9115 - loss: 0.2583 - precision: 0.8646 - recall: 0.9171 - val_AUC: 0.6835 - val_accuracy: 0.6891 - val_loss: 0.9197 - val_precision: 0.6176 - val_recall: 0.5526\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8622 - accuracy: 0.8164 - loss: 0.4664 - precision: 0.7503 - recall: 0.8047 \n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.7182 - accuracy: 0.6809 - loss: 0.6444 - precision: 0.5786 - recall: 0.7097 - val_AUC: 0.7532 - val_accuracy: 0.6891 - val_loss: 0.6103 - val_precision: 0.5889 - val_recall: 0.6974\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.7873 - accuracy: 0.7407 - loss: 0.5620 - precision: 0.6571 - recall: 0.7628 - val_AUC: 0.7488 - val_accuracy: 0.6943 - val_loss: 0.5819 - val_precision: 0.6076 - val_recall: 0.6316\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8167 - accuracy: 0.7786 - loss: 0.5275 - precision: 0.7323 - recall: 0.7607 - val_AUC: 0.7441 - val_accuracy: 0.6891 - val_loss: 0.5826 - val_precision: 0.6026 - val_recall: 0.6184\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8558 - accuracy: 0.7903 - loss: 0.4817 - precision: 0.7334 - recall: 0.7568 - val_AUC: 0.7375 - val_accuracy: 0.6995 - val_loss: 0.6079 - val_precision: 0.6184 - val_recall: 0.6184\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8353 - accuracy: 0.8074 - loss: 0.4975 - precision: 0.7552 - recall: 0.7684 - val_AUC: 0.7294 - val_accuracy: 0.7098 - val_loss: 0.5932 - val_precision: 0.6389 - val_recall: 0.6053\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8699 - accuracy: 0.8222 - loss: 0.4494 - precision: 0.7775 - recall: 0.7688 - val_AUC: 0.7223 - val_accuracy: 0.6891 - val_loss: 0.6141 - val_precision: 0.6053 - val_recall: 0.6053\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8867 - accuracy: 0.8410 - loss: 0.4243 - precision: 0.7952 - recall: 0.8140 - val_AUC: 0.7052 - val_accuracy: 0.6788 - val_loss: 0.6580 - val_precision: 0.5897 - val_recall: 0.6053\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9163 - accuracy: 0.8605 - loss: 0.3658 - precision: 0.8256 - recall: 0.8277 - val_AUC: 0.6978 - val_accuracy: 0.6580 - val_loss: 0.6813 - val_precision: 0.5676 - val_recall: 0.5526\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9344 - accuracy: 0.8679 - loss: 0.3233 - precision: 0.8129 - recall: 0.8333 - val_AUC: 0.7148 - val_accuracy: 0.6943 - val_loss: 0.7175 - val_precision: 0.6076 - val_recall: 0.6316\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9191 - accuracy: 0.8508 - loss: 0.3630 - precision: 0.7801 - recall: 0.8498 - val_AUC: 0.6580 - val_accuracy: 0.6062 - val_loss: 0.7545 - val_precision: 0.5000 - val_recall: 0.5658\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9479 - accuracy: 0.8973 - loss: 0.3038 - precision: 0.8667 - recall: 0.8852 - val_AUC: 0.7065 - val_accuracy: 0.6736 - val_loss: 0.7241 - val_precision: 0.5942 - val_recall: 0.5395\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9468 - accuracy: 0.9153 - loss: 0.2990 - precision: 0.9226 - recall: 0.8549 - val_AUC: 0.6879 - val_accuracy: 0.6425 - val_loss: 0.8514 - val_precision: 0.5402 - val_recall: 0.6184\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7780 - accuracy: 0.6923 - loss: 0.5806 - precision: 0.6080 - recall: 0.7096 \n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.6228 - accuracy: 0.6030 - loss: 0.6670 - precision: 0.4913 - recall: 0.5050 - val_AUC: 0.8070 - val_accuracy: 0.7668 - val_loss: 0.5672 - val_precision: 0.7183 - val_recall: 0.6711\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.7909 - accuracy: 0.7389 - loss: 0.5752 - precision: 0.6537 - recall: 0.7387 - val_AUC: 0.8113 - val_accuracy: 0.7720 - val_loss: 0.5178 - val_precision: 0.7222 - val_recall: 0.6842\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.8004 - accuracy: 0.7533 - loss: 0.5421 - precision: 0.6551 - recall: 0.7362 - val_AUC: 0.8184 - val_accuracy: 0.7824 - val_loss: 0.4946 - val_precision: 0.7576 - val_recall: 0.6579\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8350 - accuracy: 0.7677 - loss: 0.5046 - precision: 0.6978 - recall: 0.7214 - val_AUC: 0.8122 - val_accuracy: 0.7617 - val_loss: 0.5049 - val_precision: 0.7143 - val_recall: 0.6579\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8260 - accuracy: 0.7877 - loss: 0.5133 - precision: 0.7296 - recall: 0.7615 - val_AUC: 0.8176 - val_accuracy: 0.7824 - val_loss: 0.4982 - val_precision: 0.7833 - val_recall: 0.6184\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8590 - accuracy: 0.8051 - loss: 0.4738 - precision: 0.7556 - recall: 0.7777 - val_AUC: 0.8063 - val_accuracy: 0.7513 - val_loss: 0.5235 - val_precision: 0.7059 - val_recall: 0.6316\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.8663 - accuracy: 0.8034 - loss: 0.4545 - precision: 0.7235 - recall: 0.8057 - val_AUC: 0.8026 - val_accuracy: 0.7461 - val_loss: 0.5300 - val_precision: 0.7143 - val_recall: 0.5921\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9042 - accuracy: 0.8498 - loss: 0.3928 - precision: 0.7971 - recall: 0.8187 - val_AUC: 0.8068 - val_accuracy: 0.7668 - val_loss: 0.5351 - val_precision: 0.7627 - val_recall: 0.5921\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9299 - accuracy: 0.8592 - loss: 0.3507 - precision: 0.7962 - recall: 0.8708 - val_AUC: 0.8035 - val_accuracy: 0.7461 - val_loss: 0.5960 - val_precision: 0.7455 - val_recall: 0.5395\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9372 - accuracy: 0.8979 - loss: 0.3191 - precision: 0.8734 - recall: 0.8788 - val_AUC: 0.7968 - val_accuracy: 0.7513 - val_loss: 0.6269 - val_precision: 0.8043 - val_recall: 0.4868\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9521 - accuracy: 0.9086 - loss: 0.2733 - precision: 0.8888 - recall: 0.8713 - val_AUC: 0.7921 - val_accuracy: 0.7358 - val_loss: 0.6631 - val_precision: 0.7451 - val_recall: 0.5000\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9720 - accuracy: 0.9223 - loss: 0.2147 - precision: 0.8976 - recall: 0.9047 - val_AUC: 0.8023 - val_accuracy: 0.7358 - val_loss: 0.6849 - val_precision: 0.7193 - val_recall: 0.5395\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - AUC: 0.9726 - accuracy: 0.9246 - loss: 0.2137 - precision: 0.8717 - recall: 0.9489 - val_AUC: 0.7982 - val_accuracy: 0.7358 - val_loss: 0.7632 - val_precision: 0.8205 - val_recall: 0.4211\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7725 - accuracy: 0.7489 - loss: 0.5605 - precision: 0.7021 - recall: 0.6570 \n",
      "Loses: [0.581782877445221, 0.5489885210990906, 0.4910860061645508, 0.5820185542106628, 0.5787131786346436] 0.5565178275108338 0.034983587928197044\n",
      "AUCs: [0.7790189981460571, 0.7867167592048645, 0.845363438129425, 0.7733661532402039, 0.7608867883682251] 0.7890704274177551 0.029381680608714\n",
      "Accuracies: [0.7231404781341553, 0.7479338645935059, 0.7809917330741882, 0.6983470916748047, 0.7219917178153992] 0.7344809770584106 0.02805165518609149\n",
      "Precisions: [0.6320754885673523, 0.6931818127632141, 0.7058823704719543, 0.6095238327980042, 0.6555555462837219] 0.6592438101768494 0.03619596791391974\n",
      "Recals: [0.7052631378173828, 0.6421052813529968, 0.75789475440979, 0.6666666865348816, 0.621052622795105] 0.6785964965820312 0.048548017500926126\n"
     ]
    }
   ],
   "source": [
    "# crossfold\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "if \"datavalset\" not in locals():\n",
    "    datavalset = pickle.loads(\n",
    "        (TEMP_PATH / f\"train-val-test-set-{splitPartCount}-{splitSeed}-{hoursPerWindow}.pkl\").read_bytes()\n",
    "    )\n",
    "\n",
    "loses = []\n",
    "aucs = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recals = []\n",
    "for i, (npTrainX, trainY, npValX, valY, npTestX, testY) in enumerate(datavalset):\n",
    "    npTrainX = np.nan_to_num(npTrainX, nan=0)\n",
    "    npValX = np.nan_to_num(npValX, nan=0)\n",
    "    npTestX = np.nan_to_num(npTestX, nan=0)\n",
    "\n",
    "    model = createModel(npTrainX.shape[1], npTrainX.shape[2])\n",
    "\n",
    "    neg, pos = np.bincount(trainY)\n",
    "    weight0 = (1 / neg) * (len(trainY)) / 2.0\n",
    "    weight1 = (1 / pos) * (len(trainY)) / 2.0\n",
    "    weight = {0: weight0, 1: weight1}\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    trainY = np.array(trainY)\n",
    "    valY = np.array(valY)\n",
    "    testY = np.array(testY)\n",
    "\n",
    "    model.fit(\n",
    "        npTrainX,\n",
    "        trainY,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(npValX, valY),\n",
    "        class_weight=weight,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    loss, auc, accuracy, precison, recal = model.evaluate(npTestX, testY)\n",
    "    loses.append(loss)\n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precison)\n",
    "    recals.append(recal)\n",
    "\n",
    "    pass\n",
    "\n",
    "print(\"Loses:\", loses, np.mean(loses), np.std(loses))\n",
    "print(\"AUCs:\", aucs, np.mean(aucs), np.std(aucs))\n",
    "print(\"Accuracies:\", accuracies, np.mean(accuracies), np.std(accuracies))\n",
    "print(\"Precisions:\", precisions, np.mean(precisions), np.std(precisions))\n",
    "print(\"Recals:\", recals, np.mean(recals), np.std(recals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
