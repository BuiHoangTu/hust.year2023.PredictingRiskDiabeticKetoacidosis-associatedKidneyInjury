{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "input"
    ]
   },
   "outputs": [],
   "source": [
    "splitPartCount = 5\n",
    "splitSeed = 27\n",
    "hoursPerWindow = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1213"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.class_patient import Patients\n",
    "\n",
    "\n",
    "patients = Patients.loadPatients()\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill measures whose null represent false value\n",
    "\n",
    "from constants import NULLABLE_MEASURES\n",
    "\n",
    "\n",
    "nullableMeasures = NULLABLE_MEASURES\n",
    "\n",
    "for measureName in nullableMeasures:\n",
    "    patients.fillMissingMeasureValue(measureName, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pco2 917\n",
      "ph 954\n",
      "po2 917\n",
      "albumin 406\n",
      "hba1c 326\n",
      "lymphocyte 446\n",
      "height 415\n",
      "urine-ketone 294\n",
      "crp 19\n"
     ]
    }
   ],
   "source": [
    "# remove measures with less than 80% of data\n",
    "\n",
    "measures = patients.getMeasures()\n",
    "\n",
    "for measure, count in measures.items():\n",
    "    if count < len(patients) * 80 / 100:\n",
    "        patients.removeMeasures([measure])\n",
    "        print(measure, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove patients with less than 80% of data\n",
    "\n",
    "patients.removePatientByMissingFeatures()\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitedPatients = patients.split(splitPartCount, splitSeed)\n",
    "\n",
    "len(splitedPatients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>akd</th>\n",
       "      <th>ag</th>\n",
       "      <th>age</th>\n",
       "      <th>bg</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bun</th>\n",
       "      <th>calcium</th>\n",
       "      <th>...</th>\n",
       "      <th>race</th>\n",
       "      <th>rr</th>\n",
       "      <th>saps2</th>\n",
       "      <th>sbp</th>\n",
       "      <th>scr</th>\n",
       "      <th>sofa</th>\n",
       "      <th>use_NaHCO3</th>\n",
       "      <th>uti</th>\n",
       "      <th>wbc</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19054290</td>\n",
       "      <td>20046699</td>\n",
       "      <td>30643955</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14866589</td>\n",
       "      <td>20066152</td>\n",
       "      <td>33060916</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14849360</td>\n",
       "      <td>20152551</td>\n",
       "      <td>32817197</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>UNABLE TO OBTAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16171124</td>\n",
       "      <td>20167052</td>\n",
       "      <td>38239449</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>HISPANIC/LATINO - DOMINICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16815664</td>\n",
       "      <td>20240670</td>\n",
       "      <td>37751533</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15517352</td>\n",
       "      <td>29801212</td>\n",
       "      <td>32814591</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10383045</td>\n",
       "      <td>29899941</td>\n",
       "      <td>39755932</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15679298</td>\n",
       "      <td>29905973</td>\n",
       "      <td>39834726</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10912213</td>\n",
       "      <td>29911812</td>\n",
       "      <td>34040470</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17657693</td>\n",
       "      <td>29997858</td>\n",
       "      <td>31578780</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id   hadm_id   stay_id    akd  ag  age  bg  bicarbonate  bun  \\\n",
       "0     19054290  20046699  30643955  False NaN   65 NaN          NaN  NaN   \n",
       "0     14866589  20066152  33060916  False NaN   37 NaN          NaN  NaN   \n",
       "0     14849360  20152551  32817197  False NaN   59 NaN          NaN  NaN   \n",
       "0     16171124  20167052  38239449  False NaN   37 NaN          NaN  NaN   \n",
       "0     16815664  20240670  37751533  False NaN   42 NaN          NaN  NaN   \n",
       "..         ...       ...       ...    ...  ..  ...  ..          ...  ...   \n",
       "0     15517352  29801212  32814591  False NaN   20 NaN          NaN  NaN   \n",
       "0     10383045  29899941  39755932  False NaN   58 NaN          NaN  NaN   \n",
       "0     15679298  29905973  39834726  False NaN   50 NaN          NaN  NaN   \n",
       "0     10912213  29911812  34040470  False NaN   47 NaN          NaN  NaN   \n",
       "0     17657693  29997858  31578780  False NaN   34 NaN          NaN  NaN   \n",
       "\n",
       "    calcium  ...                         race  rr  saps2  sbp  scr  sofa  \\\n",
       "0       NaN  ...                        WHITE NaN     34  NaN  NaN     3   \n",
       "0       NaN  ...                        WHITE NaN     22  NaN  NaN     2   \n",
       "0       NaN  ...             UNABLE TO OBTAIN NaN     22  NaN  NaN     4   \n",
       "0       NaN  ...  HISPANIC/LATINO - DOMINICAN NaN     15  NaN  NaN     2   \n",
       "0       NaN  ...       BLACK/AFRICAN AMERICAN NaN     27  NaN  NaN     2   \n",
       "..      ...  ...                          ...  ..    ...  ...  ...   ...   \n",
       "0       NaN  ...                        WHITE NaN     30  NaN  NaN     1   \n",
       "0       NaN  ...                        WHITE NaN     23  NaN  NaN     1   \n",
       "0       NaN  ...                        WHITE NaN     32  NaN  NaN     3   \n",
       "0       NaN  ...                        WHITE NaN     23  NaN  NaN     2   \n",
       "0       NaN  ...                        OTHER NaN     19  NaN  NaN     1   \n",
       "\n",
       "    use_NaHCO3  uti wbc  weight  \n",
       "0          0.0    0 NaN   74.50  \n",
       "0          0.0    0 NaN     NaN  \n",
       "0          0.0    0 NaN     NaN  \n",
       "0          0.0    0 NaN     NaN  \n",
       "0          NaN    0 NaN   43.00  \n",
       "..         ...  ...  ..     ...  \n",
       "0          NaN    0 NaN     NaN  \n",
       "0          0.0    0 NaN   59.40  \n",
       "0          0.0    0 NaN   47.40  \n",
       "0          0.0    0 NaN   89.05  \n",
       "0          0.0    0 NaN     NaN  \n",
       "\n",
       "[242 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Timedelta\n",
    "\n",
    "\n",
    "splitedPatients[0].getMeasuresBetween(Timedelta(-6), Timedelta(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTest():\n",
    "    for i in range(splitedPatients.__len__()):\n",
    "        testPatients = splitedPatients[i]\n",
    "\n",
    "        trainPatientsList = splitedPatients[:i] + splitedPatients[i + 1 :]\n",
    "        trainPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatientsList:\n",
    "            trainPatients += trainPatientsElem\n",
    "\n",
    "        yield trainPatients, testPatients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967 242\n",
      "967 242\n",
      "967 242\n",
      "967 242\n",
      "968 241\n"
     ]
    }
   ],
   "source": [
    "for trainPatients, testPatients in trainTest():\n",
    "    print(len(trainPatients.patientList), len(testPatients.patientList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0 created\n",
      "Dataset 1 created\n",
      "Dataset 2 created\n",
      "Dataset 3 created\n",
      "Dataset 4 created\n"
     ]
    }
   ],
   "source": [
    "from constants import CATEGORICAL_MEASURES, TEMP_PATH\n",
    "from utils.dl_prepare_data import patientsToNumpy\n",
    "\n",
    "\n",
    "dataset = []\n",
    "for i, (trainPatients, testPatients) in enumerate(trainTest()):\n",
    "    # trainPatients.fillMissingMeasureValue(CATEGORICAL_MEASURES, 0)\n",
    "    npTrainX, categoryEncoder, numericEncoder, oulier, columns = patientsToNumpy(\n",
    "        trainPatients, hoursPerWindow, CATEGORICAL_MEASURES\n",
    "    )\n",
    "\n",
    "    # testPatients.fillMissingMeasureValue(CATEGORICAL_MEASURES, 0)\n",
    "    npTestX, *_ = patientsToNumpy(\n",
    "        testPatients,\n",
    "        hoursPerWindow,\n",
    "        CATEGORICAL_MEASURES,\n",
    "        columns,\n",
    "        categoryEncoder,\n",
    "        numericEncoder,\n",
    "        oulier,\n",
    "    )\n",
    "    trainY = [p.akdPositive for p in trainPatients]\n",
    "    testY = [p.akdPositive for p in testPatients]\n",
    "\n",
    "    dataset.append((npTrainX, trainY, npTestX, testY))\n",
    "\n",
    "    print(f\"Dataset {i} created\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from constants import CATEGORICAL_MEASURES\n",
    "# from utils.dl_prepare_data import patientsToNumpy\n",
    "\n",
    "\n",
    "# for i, (trainPatients, testPatients) in enumerate(trainTest()):\n",
    "#     if i != 3: \n",
    "#         continue\n",
    "    \n",
    "#     trainPatients.fillMissingMeasureValue(CATEGORICAL_MEASURES, 0)\n",
    "#     npTrainX, categoryEncoder, numericEncoder, oulier, columns = patientsToNumpy(\n",
    "#         trainPatients, hoursPerWindow, CATEGORICAL_MEASURES\n",
    "#     )\n",
    "\n",
    "#     testPatients.fillMissingMeasureValue(CATEGORICAL_MEASURES, 0)\n",
    "#     npTestX, *_ = patientsToNumpy(\n",
    "#         testPatients,\n",
    "#         hoursPerWindow,\n",
    "#         CATEGORICAL_MEASURES,\n",
    "#         columns,\n",
    "#         categoryEncoder,\n",
    "#         numericEncoder,\n",
    "#         oulier,\n",
    "#     )\n",
    "#     trainY = [p.akdPositive for p in trainPatients]\n",
    "#     testY = [p.akdPositive for p in testPatients]\n",
    "\n",
    "#     dataset.append((npTrainX, trainY, npTestX, testY))\n",
    "\n",
    "#     print(f\"Dataset {i} created\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41441534"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "(TEMP_PATH / f\"dataset-{splitPartCount}-{splitSeed}-{hoursPerWindow}.pkl\").write_bytes(\n",
    "    pickle.dumps(dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from constants import TEMP_PATH\n",
    "\n",
    "# load if not exist dataset\n",
    "if \"dataset\" not in locals():\n",
    "    dataset = pickle.loads(\n",
    "        (TEMP_PATH / f\"dataset-{splitPartCount}-{splitSeed}-{hoursPerWindow}.pkl\").read_bytes()\n",
    "    )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25 13:44:54.744718: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-25 13:44:54.764275: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-25 13:44:55.177927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "def createModel(timeSteps, features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(timeSteps, features)))\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25 13:44:55.385434: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-25 13:44:55.400490: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/tu/codepy/hust.year2023.PredictingRiskDiabeticKetoacidosis-associatedKidneyInjury/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath={0: 0.8250853242320819, 1: 1.269028871391076}. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m weight1 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m pos) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mlen\u001b[39m(trainY)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m\n\u001b[1;32m     14\u001b[0m weight \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: weight0, \u001b[38;5;241m1\u001b[39m: weight1}\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m trainY \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(trainY)\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(npTrainX, trainY, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[0;32m~/codepy/hust.year2023.PredictingRiskDiabeticKetoacidosis-associatedKidneyInjury/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/codepy/hust.year2023.PredictingRiskDiabeticKetoacidosis-associatedKidneyInjury/.venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:262\u001b[0m, in \u001b[0;36mload_weights\u001b[0;34m(model, filepath, skip_mismatch, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m             legacy_h5_format\u001b[38;5;241m.\u001b[39mload_weights_from_hdf5_group(f, model)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` and `.weights.h5` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles, or legacy V1/V2 `.h5` files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: File format not supported: filepath={0: 0.8250853242320819, 1: 1.269028871391076}. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files."
     ]
    }
   ],
   "source": [
    "# crossfold\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "results = []\n",
    "for i, (npTrainX, trainY, npTestX, testY) in enumerate(dataset):\n",
    "    model = createModel(npTrainX.shape[1], npTrainX.shape[2])\n",
    "    \n",
    "    neg, pos = np.bincount(trainY)\n",
    "    weight0 = (1 / neg) * (len(trainY)) / 2.0\n",
    "    weight1 = (1 / pos) * (len(trainY)) / 2.0\n",
    "    weight = {0: weight0, 1: weight1}\n",
    "    model.load_weights(weight)\n",
    "    \n",
    "    trainY = np.array(trainY)\n",
    "    model.fit(npTrainX, trainY, epochs=20, batch_size=32, validation_split=0.2)\n",
    "    \n",
    "    testY = np.array(testY)\n",
    "    result = model.evaluate(npTestX, testY)\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"Dataset {i} result: {result}\")\n",
    "    pass\n",
    "\n",
    "print(\"Mean:\", np.mean(results))\n",
    "print(\"Std:\", np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586 381\n",
      "967\n",
      "0.8250853242320819\n",
      "1.269028871391076\n",
      "2.094114195623158\n"
     ]
    }
   ],
   "source": [
    "print(neg, pos)\n",
    "print(len(trainY))\n",
    "print(weight0)\n",
    "print((1 / pos) * (len(trainY)) / 2.0)\n",
    "print(weight0 + weight1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037094429139883686"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_count = np.isnan(npTrainX).sum()\n",
    "nan_count / npTrainX.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npTrainX.shape[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
