{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "input"
    ]
   },
   "outputs": [],
   "source": [
    "splitPartCount = 5\n",
    "splitSeed = 27\n",
    "hoursPerWindow = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.class_patient import Patients\n",
    "\n",
    "\n",
    "patients = Patients.loadPatients()\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill measures whose null represent false value\n",
    "\n",
    "from constants import NULLABLE_MEASURES\n",
    "\n",
    "\n",
    "nullableMeasures = NULLABLE_MEASURES\n",
    "\n",
    "for measureName in nullableMeasures:\n",
    "    patients.fillMissingMeasureValue(measureName, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove measures with less than 80% of data\n",
    "\n",
    "measures = patients.getMeasures()\n",
    "\n",
    "for measure, count in measures.items():\n",
    "    if count < len(patients) * 80 / 100:\n",
    "        patients.removeMeasures([measure])\n",
    "        print(measure, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove patients with less than 80% of data\n",
    "\n",
    "patients.removePatientByMissingFeatures()\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove patients with positive tag in first 12 hours\n",
    "\n",
    "from pandas import Timedelta\n",
    "\n",
    "\n",
    "patients.removePatientAkiEarly(Timedelta(hours=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total \", len(patients))\n",
    "print(\"AKI \", sum([1 for p in patients if p.akdPositive]))\n",
    "print(\"Ratio \", sum([1 for p in patients if p.akdPositive]) / len(patients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitedPatients = patients.split(splitPartCount, splitSeed)\n",
    "\n",
    "len(splitedPatients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitedPatients = patients.split(splitPartCount, splitSeed)\n",
    "\n",
    "\n",
    "def trainTest():\n",
    "    for i in range(splitedPatients.__len__()):\n",
    "        testPatients = splitedPatients[i]\n",
    "\n",
    "        trainPatientsList = splitedPatients[:i] + splitedPatients[i + 1 :]\n",
    "        trainPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatientsList:\n",
    "            trainPatients += trainPatientsElem\n",
    "\n",
    "        yield trainPatients, testPatients\n",
    "\n",
    "\n",
    "def trainValTest():\n",
    "    for i in range(splitedPatients.__len__()):\n",
    "        testPatients = splitedPatients[i]\n",
    "\n",
    "        trainPatientsList = splitedPatients[:i] + splitedPatients[i + 1 :]\n",
    "        trainPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatientsList:\n",
    "            trainPatients += trainPatientsElem\n",
    "\n",
    "        *trainPatients, valPatients = trainPatients.split(5, 27)\n",
    "        tmpPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatients:\n",
    "            tmpPatients += trainPatientsElem\n",
    "        trainPatients = tmpPatients\n",
    "\n",
    "        yield trainPatients, valPatients, testPatients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trainPatients, testPatients in trainTest():\n",
    "    print(len(trainPatients.patientList), len(testPatients.patientList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate static and dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    Concatenate,\n",
    "    Masking,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "def createModel2(timeSteps, timeFeatures, staticFeatures):\n",
    "    # time series layers\n",
    "    timeInputLayer = Input(shape=(timeSteps, timeFeatures))\n",
    "    maskingLayer = Masking(mask_value=0.0)(timeInputLayer)\n",
    "    # cnnLayer = Conv1D(64, 3, activation=\"relu\", kernel_regularizer=l2(0.01))(maskingLayer)\n",
    "    # batNormCnn = BatchNormalization()(cnnLayer)\n",
    "    # poolingLayer = MaxPooling1D(2)(batNormCnn)\n",
    "    seriesLayer = LSTM(64, return_sequences=True)(maskingLayer)\n",
    "    seriesLayer2 = LSTM(64)(seriesLayer)\n",
    "    seriesDense = Dense(32, activation=\"relu\")(seriesLayer2)\n",
    "    \n",
    "\n",
    "    # static layers\n",
    "    staticInputLayer = Input(shape=(staticFeatures,))\n",
    "    staticLayer = Dense(32, activation=\"relu\")(staticInputLayer)\n",
    "\n",
    "    # combine layers\n",
    "    combined = Concatenate(axis=1)([seriesDense, staticLayer])\n",
    "    dense1 = Dense(16, activation=\"relu\")(combined)\n",
    "    dropout1 = Dropout(0.5)(dense1)\n",
    "    dense2 = Dense(1, activation=\"sigmoid\")(dropout1)\n",
    "\n",
    "    model = Model(inputs=[timeInputLayer, staticInputLayer], outputs=dense2)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"AUC\", \"accuracy\", \"precision\", \"recall\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prepare_data import normalizeData, patientsToNumpy\n",
    "from constants import CATEGORICAL_MEASURES\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "loses = []\n",
    "aucs = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recals = []\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "models = []\n",
    "\n",
    "for i, (trainPatients, valPatients, testPatients) in enumerate(trainValTest()):\n",
    "    npTrainX, categoryEncoder, numericEncoder, oulier, columns = patientsToNumpy(\n",
    "        trainPatients, \n",
    "        hoursPerWindow,\n",
    "        CATEGORICAL_MEASURES,\n",
    "        timeSeriesOnly=True,\n",
    "        fromHour=0,\n",
    "        toHour=12,\n",
    "    )\n",
    "\n",
    "    npTestX, *_ = patientsToNumpy(\n",
    "        testPatients,\n",
    "        hoursPerWindow,\n",
    "        CATEGORICAL_MEASURES,\n",
    "        columns,\n",
    "        categoryEncoder,\n",
    "        numericEncoder,\n",
    "        oulier,\n",
    "        timeSeriesOnly=True,\n",
    "        fromHour=0,\n",
    "        toHour=12,\n",
    "    )\n",
    "\n",
    "    npValX, *_ = patientsToNumpy(\n",
    "        valPatients,\n",
    "        hoursPerWindow,\n",
    "        CATEGORICAL_MEASURES,\n",
    "        columns,\n",
    "        categoryEncoder,\n",
    "        numericEncoder,\n",
    "        oulier,\n",
    "        timeSeriesOnly=True,\n",
    "        fromHour=0,\n",
    "        toHour=12,\n",
    "    )\n",
    "\n",
    "    npTrainX = np.nan_to_num(npTrainX, nan=0)\n",
    "    npTestX = np.nan_to_num(npTestX, nan=0)\n",
    "    npValX = np.nan_to_num(npValX, nan=0)\n",
    "\n",
    "    ################### Static ###################\n",
    "    staticTrainX = trainPatients.getMeasuresBetween(measureTypes=\"static\")\n",
    "    staticTestX = testPatients.getMeasuresBetween(measureTypes=\"static\")\n",
    "    staticValX = valPatients.getMeasuresBetween(measureTypes=\"static\")\n",
    "\n",
    "    staticTrainX = staticTrainX.drop(columns=[\"subject_id\", \"hadm_id\", \"stay_id\", \"akd\"])\n",
    "    staticTestX = staticTestX.drop(columns=[\"subject_id\", \"hadm_id\", \"stay_id\", \"akd\"])\n",
    "    staticValX = staticValX.drop(columns=[\"subject_id\", \"hadm_id\", \"stay_id\", \"akd\"])\n",
    "\n",
    "    staticTrainX, staticTestX, staticValX = normalizeData(\n",
    "        staticTrainX, staticTestX, staticValX\n",
    "    )\n",
    "\n",
    "    staticLen = len(staticTrainX.columns)\n",
    "\n",
    "    staticTrainX = staticTrainX.to_numpy().astype(np.float32)\n",
    "    staticTestX = staticTestX.to_numpy().astype(np.float32)\n",
    "    staticValX = staticValX.to_numpy().astype(np.float32) # type: ignore\n",
    "\n",
    "    staticTrainX = np.nan_to_num(staticTrainX, nan=0)\n",
    "    staticTestX = np.nan_to_num(staticTestX, nan=0)\n",
    "\n",
    "    ################### labels ###################\n",
    "    trainY = [p.akdPositive for p in trainPatients]\n",
    "    testY = [p.akdPositive for p in testPatients]\n",
    "    valY = [p.akdPositive for p in valPatients]\n",
    "\n",
    "    model = createModel2(npTrainX.shape[1], npTrainX.shape[2], staticLen)\n",
    "\n",
    "    neg, pos = np.bincount(trainY)\n",
    "    weight0 = (1 / neg) * (len(trainY)) / 2.0\n",
    "    weight1 = (1 / pos) * (len(trainY)) / 2.0\n",
    "    weight = {0: weight0, 1: weight1}\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=50, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    trainY = np.array(trainY)\n",
    "    history = model.fit(\n",
    "        [npTrainX, staticTrainX],\n",
    "        trainY,\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        validation_data=([npValX, staticValX], np.array(valY)),\n",
    "        class_weight=weight,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "    models.append(model)\n",
    "\n",
    "    testY = np.array(testY)\n",
    "    loss, auc, accuracy, precison, recal = model.evaluate([npTestX, staticTestX], testY)\n",
    "\n",
    "    loses.append(loss)\n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precison)\n",
    "    recals.append(recal)\n",
    "\n",
    "    train_loss_list.append(history.history['loss'])\n",
    "    val_loss_list.append(history.history['val_loss'])\n",
    "\n",
    "    pass\n",
    "\n",
    "print(\"Loses:\", loses, np.mean(loses), np.std(loses))\n",
    "print(\"AUCs:\", aucs, np.mean(aucs), np.std(aucs))\n",
    "print(\"Accuracies:\", accuracies, np.mean(accuracies), np.std(accuracies))\n",
    "print(\"Precisions:\", precisions, np.mean(precisions), np.std(precisions))\n",
    "print(\"Recals:\", recals, np.mean(recals), np.std(recals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, train_loss in enumerate(train_loss_list):\n",
    "    plt.plot(\n",
    "        range(1, len(train_loss) + 1), train_loss, label=f\"Fold {i+1} Training Loss\"\n",
    "    )\n",
    "plt.title(\"Training Loss for Each Fold\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the validation loss for each fold\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, val_loss in enumerate(val_loss_list):\n",
    "    plt.plot(range(1, len(val_loss) + 1), val_loss, label=f\"Fold {i+1} Validation Loss\")\n",
    "plt.title(\"Validation Loss for Each Fold\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
