{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import externally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "\n",
    "# # Add the parent directory to the sys.path\n",
    "# parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "# if parent_dir not in sys.path:\n",
    "#     sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from constants import NULLABLE_MEASURES, TEMP_PATH\n",
    "from utils.class_patient import Patients\n",
    "\n",
    "patients = Patients.loadPatients(False, TEMP_PATH / \"learning_data-org.json\")\n",
    "patients.fillMissingMeasureValue(NULLABLE_MEASURES, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove features with more than 20% missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove measures with less than 80% of data\n",
    "\n",
    "measures = patients.getMeasures()\n",
    "\n",
    "for measure, count in measures.items():\n",
    "    if count < len(patients) * 80 / 100:\n",
    "        patients.removeMeasures([measure])\n",
    "        print(measure, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove patients with more than 20% missing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.removePatientByMissingFeatures()\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfData = patients.getMeasuresBetween(pd.Timedelta(hours=-6), pd.Timedelta(hours=24), \"first\")\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(patients.getMeasures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akdCount = sum([p.akdPositive for p in patients.patientList])\n",
    "\n",
    "akdCount / len(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import CATEGORICAL_MEASURES\n",
    "\n",
    "\n",
    "idColumns = [\"subject_id\", \"hadm_id\", \"stay_id\"]\n",
    "categoryColumns = CATEGORICAL_MEASURES\n",
    "labelColumn = \"akd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitedPatients = patients.split(5, 27)\n",
    "\n",
    "\n",
    "def trainTest():\n",
    "    for i in range(splitedPatients.__len__()):\n",
    "        testPatients = splitedPatients[i]\n",
    "\n",
    "        trainPatientsList = splitedPatients[:i] + splitedPatients[i + 1 :]\n",
    "        trainPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatientsList:\n",
    "            trainPatients += trainPatientsElem\n",
    "\n",
    "        yield trainPatients, testPatients\n",
    "\n",
    "\n",
    "def trainValTest():\n",
    "    for i in range(splitedPatients.__len__()):\n",
    "        testPatients = splitedPatients[i]\n",
    "\n",
    "        trainPatientsList = splitedPatients[:i] + splitedPatients[i + 1 :]\n",
    "        trainPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatientsList:\n",
    "            trainPatients += trainPatientsElem\n",
    "\n",
    "        *trainPatients, valPatients = trainPatients.split(5, 27)\n",
    "        tmpPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatients:\n",
    "            tmpPatients += trainPatientsElem\n",
    "        trainPatients = tmpPatients\n",
    "\n",
    "        yield trainPatients, valPatients, testPatients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "input"
    ]
   },
   "outputs": [],
   "source": [
    "how = \"first\"\n",
    "\n",
    "\n",
    "def createModel():\n",
    "    from tabpfn import TabPFNClassifier\n",
    "\n",
    "    return TabPFNClassifier(device=\"cuda\", N_ensemble_configurations=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without fill missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from utils.prepare_data import normalizeData\n",
    "\n",
    "\n",
    "accuracy_score_list = []\n",
    "precision_score_list = []\n",
    "recall_score_list = []\n",
    "auc_score_list = []\n",
    "for trainPatients, testPatients in trainTest():\n",
    "    dfTrain = trainPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how\n",
    "    )\n",
    "    dfTrain = dfTrain.drop(columns=idColumns)\n",
    "\n",
    "    dfTest = testPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how\n",
    "    )\n",
    "    dfTest = dfTest.drop(columns=idColumns)\n",
    "\n",
    "    dfTrain, dfTest, _ = normalizeData(dfTrain, dfTest)\n",
    "\n",
    "    X_train = dfTrain.drop(columns=[labelColumn])\n",
    "    y_train = dfTrain[labelColumn]\n",
    "\n",
    "    X_test = dfTest.drop(columns=[labelColumn])\n",
    "    y_test = dfTest[labelColumn]\n",
    "\n",
    "    model = createModel()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # For AUC\n",
    "\n",
    "    accuracy_score_list.append(accuracy_score(y_test, y_pred))\n",
    "    precision_score_list.append(precision_score(y_test, y_pred))\n",
    "    recall_score_list.append(recall_score(y_test, y_pred))\n",
    "    auc_score_list.append(roc_auc_score(y_test, y_pred_proba))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Average AUC: {np.mean(auc_score_list)}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_score_list)}\")\n",
    "print(f\"Average Precision: {np.mean(precision_score_list)}\")\n",
    "print(f\"Average Recall: {np.mean(recall_score_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing with knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from utils.prepare_data import normalizeAndFillData\n",
    "\n",
    "\n",
    "accuracy_score_list_knn = []\n",
    "precision_score_list_knn = []\n",
    "recall_score_list_knn = []\n",
    "auc_score_list_knn = []\n",
    "for trainPatients, testPatients in trainTest():\n",
    "    dfTrain = trainPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how\n",
    "    )\n",
    "    dfTrain = dfTrain.drop(columns=idColumns)\n",
    "\n",
    "    dfTest = testPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how\n",
    "    )\n",
    "    dfTest = dfTest.drop(columns=idColumns)\n",
    "\n",
    "    dfTrain, dfTest, _ = normalizeAndFillData(dfTrain, dfTest)\n",
    "\n",
    "    X_train = dfTrain.drop(columns=[labelColumn])\n",
    "    y_train = dfTrain[labelColumn]\n",
    "\n",
    "    X_test = dfTest.drop(columns=[labelColumn])\n",
    "    y_test = dfTest[labelColumn]\n",
    "\n",
    "    model = createModel()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # For AUC\n",
    "\n",
    "    accuracy_score_list_knn.append(accuracy_score(y_test, y_pred))\n",
    "    precision_score_list_knn.append(precision_score(y_test, y_pred))\n",
    "    recall_score_list_knn.append(recall_score(y_test, y_pred))\n",
    "    auc_score_list_knn.append(roc_auc_score(y_test, y_pred_proba))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Average AUC: {np.mean(auc_score_list_knn)}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_score_list_knn)}\")\n",
    "print(f\"Average Precision: {np.mean(precision_score_list_knn)}\")\n",
    "print(f\"Average Recall: {np.mean(recall_score_list_knn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without fill missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prepare_data import encodeCategoricalData\n",
    "\n",
    "\n",
    "accuracy_score_list_val = []\n",
    "precision_score_list_val = []\n",
    "recall_score_list_val = []\n",
    "auc_score_list_val = []\n",
    "for trainPatients, testPatients in trainTest():\n",
    "    dfTrain = trainPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how\n",
    "    )\n",
    "    dfTrain = dfTrain.drop(columns=idColumns)\n",
    "\n",
    "    dfTest = testPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how\n",
    "    )\n",
    "    dfTest = dfTest.drop(columns=idColumns)\n",
    "\n",
    "    dfTrain, dfTest, _ = encodeCategoricalData(dfTrain, dfTest)\n",
    "\n",
    "    X_train = dfTrain.drop(columns=[labelColumn])\n",
    "    y_train = dfTrain[labelColumn]\n",
    "\n",
    "    X_test = dfTest.drop(columns=[labelColumn])\n",
    "    y_test = dfTest[labelColumn]\n",
    "\n",
    "    model = createModel()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # For AUC\n",
    "\n",
    "    accuracy_score_list_val.append(accuracy_score(y_test, y_pred))\n",
    "    precision_score_list_val.append(precision_score(y_test, y_pred))\n",
    "    recall_score_list_val.append(recall_score(y_test, y_pred))\n",
    "    auc_score_list_val.append(roc_auc_score(y_test, y_pred_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f\"Average AUC: {np.mean(auc_score_list_val)}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_score_list_val)}\")\n",
    "print(f\"Average Precision: {np.mean(precision_score_list_val)}\")\n",
    "print(f\"Average Recall: {np.mean(recall_score_list_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prepare_data import encodeCategoricalData\n",
    "\n",
    "\n",
    "accuracy_score_list_val_knn = []\n",
    "precision_score_list_val_knn = []\n",
    "recall_score_list_val_knn = []\n",
    "auc_score_list_val_knn = []\n",
    "for trainPatients, testPatients in trainTest():\n",
    "    dfTrain = trainPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how\n",
    "    )\n",
    "    dfTrain = dfTrain.drop(columns=idColumns)\n",
    "\n",
    "    dfTest = testPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how\n",
    "    )\n",
    "    dfTest = dfTest.drop(columns=idColumns)\n",
    "\n",
    "    dfTrain, dfTest, _ = encodeCategoricalData(dfTrain, dfTest)\n",
    "\n",
    "    X_train = dfTrain.drop(columns=[labelColumn])\n",
    "    y_train = dfTrain[labelColumn]\n",
    "\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "\n",
    "    X_test = dfTest.drop(columns=[labelColumn])\n",
    "    y_test = dfTest[labelColumn]\n",
    "\n",
    "    model = createModel()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # For AUC\n",
    "\n",
    "    accuracy_score_list_val_knn.append(accuracy_score(y_test, y_pred))\n",
    "    precision_score_list_val_knn.append(precision_score(y_test, y_pred))\n",
    "    recall_score_list_val_knn.append(recall_score(y_test, y_pred))\n",
    "    auc_score_list_val_knn.append(roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average AUC: {np.mean(auc_score_list_val_knn)}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_score_list_val_knn)}\")\n",
    "print(f\"Average Precision: {np.mean(precision_score_list_val_knn)}\")\n",
    "print(f\"Average Recall: {np.mean(recall_score_list_val_knn)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
