{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:42:10.294412Z",
     "iopub.status.busy": "2024-06-29T09:42:10.290776Z",
     "iopub.status.idle": "2024-06-29T09:44:10.196341Z",
     "shell.execute_reply": "2024-06-29T09:44:10.191372Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from constants import NULLABLE_MEASURES\n",
    "from utils.class_patient import Patients\n",
    "\n",
    "patients = Patients.loadPatients()\n",
    "patients.fillMissingMeasureValue(NULLABLE_MEASURES, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove features with more than 20% missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:44:10.204035Z",
     "iopub.status.busy": "2024-06-29T09:44:10.203099Z",
     "iopub.status.idle": "2024-06-29T09:44:10.260326Z",
     "shell.execute_reply": "2024-06-29T09:44:10.259742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pco2 917\n",
      "ph 954\n",
      "po2 917\n",
      "albumin 406\n",
      "hba1c 326\n",
      "lymphocyte 446\n",
      "height 415\n",
      "urine-ketone 294\n",
      "crp 19\n"
     ]
    }
   ],
   "source": [
    "# remove measures with less than 80% of data\n",
    "\n",
    "measures = patients.getMeasures()\n",
    "\n",
    "for measure, count in measures.items():\n",
    "    if count < len(patients) * 80 / 100:\n",
    "        patients.removeMeasures([measure])\n",
    "        print(measure, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove patients with more than 20% missing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:44:10.264754Z",
     "iopub.status.busy": "2024-06-29T09:44:10.264420Z",
     "iopub.status.idle": "2024-06-29T09:44:10.283108Z",
     "shell.execute_reply": "2024-06-29T09:44:10.282866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1206"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients.removePatientByMissingFeatures()\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:44:10.284355Z",
     "iopub.status.busy": "2024-06-29T09:44:10.284242Z",
     "iopub.status.idle": "2024-06-29T09:44:10.298441Z",
     "shell.execute_reply": "2024-06-29T09:44:10.297535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'age': 1206,\n",
       "         'chronic_pulmonary_disease': 1206,\n",
       "         'ckd_stage': 1206,\n",
       "         'congestive_heart_failure': 1206,\n",
       "         'dka_type': 1206,\n",
       "         'gender': 1206,\n",
       "         'history_aci': 1206,\n",
       "         'history_ami': 1206,\n",
       "         'hypertension': 1206,\n",
       "         'liver_disease': 1206,\n",
       "         'macroangiopathy': 1206,\n",
       "         'malignant_cancer': 1206,\n",
       "         'mechanical_ventilation': 1206,\n",
       "         'microangiopathy': 1206,\n",
       "         'oasis': 1206,\n",
       "         'preiculos': 1206,\n",
       "         'race': 1206,\n",
       "         'saps2': 1206,\n",
       "         'sofa': 1206,\n",
       "         'use_NaHCO3': 1206,\n",
       "         'uti': 1206,\n",
       "         'ag': 1205,\n",
       "         'bg': 1205,\n",
       "         'bicarbonate': 1205,\n",
       "         'bun': 1205,\n",
       "         'chloride': 1205,\n",
       "         'egfr': 1205,\n",
       "         'hr': 1205,\n",
       "         'potassium': 1205,\n",
       "         'scr': 1205,\n",
       "         'sodium': 1205,\n",
       "         'dbp': 1204,\n",
       "         'gcs': 1204,\n",
       "         'gcs_unable': 1204,\n",
       "         'rr': 1204,\n",
       "         'sbp': 1204,\n",
       "         'calcium': 1202,\n",
       "         'phosphate': 1202,\n",
       "         'weight': 1189,\n",
       "         'plt': 1147,\n",
       "         'hb': 1145,\n",
       "         'wbc': 1145,\n",
       "         'hematocrit': 1143,\n",
       "         'mch': 1143,\n",
       "         'mchc': 1143,\n",
       "         'mcv': 1143,\n",
       "         'rbc': 1143,\n",
       "         'rdw': 1143})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dfData = patients.getMeasuresBetween(pd.Timedelta(hours=-6), pd.Timedelta(hours=24), \"first\")\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(patients.getMeasures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:44:10.304877Z",
     "iopub.status.busy": "2024-06-29T09:44:10.304456Z",
     "iopub.status.idle": "2024-06-29T09:44:10.317413Z",
     "shell.execute_reply": "2024-06-29T09:44:10.311229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39303482587064675"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "akdCount = sum([p.akdPositive for p in patients.patientList])\n",
    "\n",
    "akdCount / len(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:44:10.327862Z",
     "iopub.status.busy": "2024-06-29T09:44:10.325122Z",
     "iopub.status.idle": "2024-06-29T09:44:10.338241Z",
     "shell.execute_reply": "2024-06-29T09:44:10.336407Z"
    }
   },
   "outputs": [],
   "source": [
    "from constants import CATEGORICAL_MEASURES\n",
    "\n",
    "\n",
    "idColumns = [\"subject_id\", \"hadm_id\", \"stay_id\"]\n",
    "categoryColumns = CATEGORICAL_MEASURES\n",
    "labelColumn = \"akd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:44:10.352029Z",
     "iopub.status.busy": "2024-06-29T09:44:10.351022Z",
     "iopub.status.idle": "2024-06-29T09:44:10.370910Z",
     "shell.execute_reply": "2024-06-29T09:44:10.369274Z"
    }
   },
   "outputs": [],
   "source": [
    "splitedPatients = patients.split(5, 27)\n",
    "\n",
    "\n",
    "def trainTest():\n",
    "    for i in range(splitedPatients.__len__()):\n",
    "        testPatients = splitedPatients[i]\n",
    "\n",
    "        trainPatientsList = splitedPatients[:i] + splitedPatients[i + 1 :]\n",
    "        trainPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatientsList:\n",
    "            trainPatients += trainPatientsElem\n",
    "\n",
    "        yield trainPatients, testPatients\n",
    "\n",
    "\n",
    "def trainValTest():\n",
    "    for i in range(splitedPatients.__len__()):\n",
    "        testPatients = splitedPatients[i]\n",
    "\n",
    "        trainPatientsList = splitedPatients[:i] + splitedPatients[i + 1 :]\n",
    "        trainPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatientsList:\n",
    "            trainPatients += trainPatientsElem\n",
    "\n",
    "        *trainPatients, valPatients = trainPatients.split(5, 27)\n",
    "        tmpPatients = Patients(patients=[])\n",
    "        for trainPatientsElem in trainPatients:\n",
    "            tmpPatients += trainPatientsElem\n",
    "        trainPatients = tmpPatients\n",
    "\n",
    "        yield trainPatients, valPatients, testPatients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:44:10.374873Z",
     "iopub.status.busy": "2024-06-29T09:44:10.374402Z",
     "iopub.status.idle": "2024-06-29T09:44:13.388015Z",
     "shell.execute_reply": "2024-06-29T09:44:13.387542Z"
    },
    "tags": [
     "input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 16:44:10.734941: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-29 16:44:10.794193: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 16:44:11.749563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<GRANDE name=grande, built=False>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GRANDE import GRANDE\n",
    "\n",
    "\n",
    "how = \"first\"\n",
    "\n",
    "def createModel():\n",
    "    import os\n",
    "\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "\n",
    "    params = {\n",
    "        \"depth\": 6,  # tree depth\n",
    "        \"n_estimators\": 1000,  # number of estimators / trees\n",
    "        \"learning_rate_weights\": 0.005,  # learning rate for leaf weights\n",
    "        \"learning_rate_index\": 0.01,  # learning rate for split indices\n",
    "        \"learning_rate_values\": 0.01,  # learning rate for split values\n",
    "        \"learning_rate_leaf\": 0.01,  # learning rate for leafs (logits)\n",
    "        \"optimizer\": \"adam\",  # optimizer\n",
    "        \"cosine_decay_steps\": 0,  # decay steps for lr schedule (CosineDecayRestarts)\n",
    "        \"loss\": \"crossentropy\",  # loss function (default 'crossentropy' for binary & multi-class classification and 'mse' for regression)\n",
    "        \"focal_loss\": False,  # use focal loss {True, False}\n",
    "        \"temperature\": 0.0,  # temperature for stochastic re-weighted GD (0.0, 1.0)\n",
    "        \"from_logits\": True,  # use logits for weighting {True, False}\n",
    "        \"use_class_weights\": True,  # use class weights for training {True, False}\n",
    "        \"dropout\": 0.0,  # dropout rate (here, dropout randomly disables individual estimators of the ensemble during training)\n",
    "        \"selected_variables\": 0.8,  # feature subset percentage (0.0, 1.0)\n",
    "        \"data_subset_fraction\": 1.0,  # data subset percentage (0.0, 1.0)\n",
    "    }\n",
    "\n",
    "    args = {\n",
    "        \"device\": \"gpu\",  # device {'cpu', 'gpu'}\n",
    "        \"epochs\": 1_000,  # number of epochs for training\n",
    "        \"early_stopping_epochs\": 25,  # patience for early stopping (best weights are restored)\n",
    "        \"batch_size\": 64,  # batch size for training\n",
    "        \"cat_idx\": [],  # put list of categorical indices\n",
    "        \"objective\": \"binary\",  # objective / task {'binary', 'classification', 'regression'}\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": 0,\n",
    "    }\n",
    "\n",
    "    return GRANDE(params=params, args=args)\n",
    "\n",
    "createModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057324b7",
   "metadata": {},
   "source": [
    "`functionize-notebook` has modified this notebook during execution. The following variables have been injected:\n",
    "\n",
    "- how: first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without fill missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:44:13.399352Z",
     "iopub.status.busy": "2024-06-29T09:44:13.398993Z",
     "iopub.status.idle": "2024-06-29T09:44:35.796464Z",
     "shell.execute_reply": "2024-06-29T09:44:35.794795Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalizeAndFillData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m dfTest \u001b[38;5;241m=\u001b[39m testPatients\u001b[38;5;241m.\u001b[39mgetMeasuresBetween(\n\u001b[1;32m     17\u001b[0m     pd\u001b[38;5;241m.\u001b[39mTimedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m), pd\u001b[38;5;241m.\u001b[39mTimedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), how, getUntilAkiPositive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m dfTest \u001b[38;5;241m=\u001b[39m dfTest\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39midColumns)\n\u001b[0;32m---> 21\u001b[0m dfTrain, dfTest, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnormalizeAndFillData\u001b[49m(dfTrain, dfTest)\n\u001b[1;32m     23\u001b[0m X_train \u001b[38;5;241m=\u001b[39m dfTrain\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[labelColumn])\n\u001b[1;32m     24\u001b[0m y_train \u001b[38;5;241m=\u001b[39m dfTrain[labelColumn]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normalizeAndFillData' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from utils.prepare_data import normalizeData\n",
    "\n",
    "\n",
    "accuracy_score_list = []\n",
    "precision_score_list = []\n",
    "recall_score_list = []\n",
    "auc_score_list = []\n",
    "for trainPatients, testPatients in trainTest():\n",
    "    dfTrain = trainPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfTrain = dfTrain.drop(columns=idColumns)\n",
    "\n",
    "    dfTest = testPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfTest = dfTest.drop(columns=idColumns)\n",
    "\n",
    "    dfTrain, dfTest, _ = normalizeAndFillData(dfTrain, dfTest)\n",
    "\n",
    "    X_train = dfTrain.drop(columns=[labelColumn])\n",
    "    y_train = dfTrain[labelColumn]\n",
    "\n",
    "    X_test = dfTest.drop(columns=[labelColumn])\n",
    "    y_test = dfTest[labelColumn]\n",
    "\n",
    "    model = createModel()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict(X_test)[:, 1]  # For AUC\n",
    "\n",
    "    accuracy_score_list.append(accuracy_score(y_test, np.round(y_pred_proba)))\n",
    "    precision_score_list.append(precision_score(y_test, np.round(y_pred_proba)))\n",
    "    recall_score_list.append(recall_score(y_test, np.round(y_pred_proba)))\n",
    "    auc_score_list.append(roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:44:35.806853Z",
     "iopub.status.busy": "2024-06-29T09:44:35.806108Z",
     "iopub.status.idle": "2024-06-29T09:44:35.817758Z",
     "shell.execute_reply": "2024-06-29T09:44:35.815312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC: nan\n",
      "Average Accuracy: nan\n",
      "Average Precision: nan\n",
      "Average Recall: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/codepy/hust.year2023.PredictingRiskDiabeticKetoacidosis-associatedKidneyInjury/.venv/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/tu/codepy/hust.year2023.PredictingRiskDiabeticKetoacidosis-associatedKidneyInjury/.venv/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Average AUC: {np.mean(auc_score_list)}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_score_list)}\")\n",
    "print(f\"Average Precision: {np.mean(precision_score_list)}\")\n",
    "print(f\"Average Recall: {np.mean(recall_score_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing with knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:44:35.824573Z",
     "iopub.status.busy": "2024-06-29T09:44:35.823649Z",
     "iopub.status.idle": "2024-06-29T10:14:57.894418Z",
     "shell.execute_reply": "2024-06-29T10:14:57.893767Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 16:44:55.588624: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-29 16:44:55.645360: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x73d6401bd080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x73d6401bd080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from utils.prepare_data import normalizeAndFillData\n",
    "\n",
    "\n",
    "accuracy_score_list_knn = []\n",
    "precision_score_list_knn = []\n",
    "recall_score_list_knn = []\n",
    "auc_score_list_knn = []\n",
    "for trainPatients, valPatients, testPatients in trainValTest():\n",
    "    dfTrain = trainPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfTrain = dfTrain.drop(columns=idColumns)\n",
    "\n",
    "    dfVal = valPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfVal = dfVal.drop(columns=idColumns)\n",
    "\n",
    "    dfTest = testPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfTest = dfTest.drop(columns=idColumns)\n",
    "\n",
    "    dfTrain, dfTest, dfVal = normalizeData(dfTrain, dfTest, dfVal)\n",
    "\n",
    "    X_train = dfTrain.drop(columns=[labelColumn])\n",
    "    y_train = dfTrain[labelColumn]\n",
    "\n",
    "    X_val = dfVal.drop(columns=[labelColumn])  # type: ignore\n",
    "    y_val = dfVal[labelColumn]  # type: ignore\n",
    "\n",
    "    X_test = dfTest.drop(columns=[labelColumn])\n",
    "    y_test = dfTest[labelColumn]\n",
    "\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_val = X_val.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "\n",
    "    model = createModel()\n",
    "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "    # y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict(X_test)[:, 1]  # For AUC\n",
    "\n",
    "    accuracy_score_list_knn.append(accuracy_score(y_test, np.round(y_pred_proba)))\n",
    "    precision_score_list_knn.append(precision_score(y_test, np.round(y_pred_proba)))\n",
    "    recall_score_list_knn.append(recall_score(y_test, np.round(y_pred_proba)))\n",
    "    auc_score_list_knn.append(roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:14:57.898808Z",
     "iopub.status.busy": "2024-06-29T10:14:57.898649Z",
     "iopub.status.idle": "2024-06-29T10:14:57.901421Z",
     "shell.execute_reply": "2024-06-29T10:14:57.901116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC: 0.7968472812125663\n",
      "Average Accuracy: 0.737152361030143\n",
      "Average Precision: 0.6866192356113968\n",
      "Average Recall: 0.6118924972004478\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Average AUC: {np.mean(auc_score_list_knn)}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_score_list_knn)}\")\n",
    "print(f\"Average Precision: {np.mean(precision_score_list_knn)}\")\n",
    "print(f\"Average Recall: {np.mean(recall_score_list_knn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without fill missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:14:57.902527Z",
     "iopub.status.busy": "2024-06-29T10:14:57.902421Z",
     "iopub.status.idle": "2024-06-29T10:43:51.280624Z",
     "shell.execute_reply": "2024-06-29T10:43:51.276209Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.prepare_data import normalizeData\n",
    "\n",
    "\n",
    "accuracy_score_list_val = []\n",
    "precision_score_list_val = []\n",
    "recall_score_list_val = []\n",
    "auc_score_list_val = []\n",
    "for trainPatients, valPatients, testPatients in trainValTest():\n",
    "    dfTrain = trainPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfTrain = dfTrain.drop(columns=idColumns)\n",
    "\n",
    "    dfVal = valPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfVal = dfVal.drop(columns=idColumns)\n",
    "\n",
    "    dfTest = testPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfTest = dfTest.drop(columns=idColumns)\n",
    "\n",
    "    dfTrain, dfTest, dfVal = normalizeData(dfTrain, dfTest, dfVal)\n",
    "\n",
    "    X_train = dfTrain.drop(columns=[labelColumn])\n",
    "    y_train = dfTrain[labelColumn]\n",
    "\n",
    "    X_val = dfVal.drop(columns=[labelColumn]) # type: ignore\n",
    "    y_val = dfVal[labelColumn] # type: ignore\n",
    "\n",
    "    X_test = dfTest.drop(columns=[labelColumn])\n",
    "    y_test = dfTest[labelColumn]\n",
    "\n",
    "    model = createModel()\n",
    "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "    # y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict(X_test)[:, 1]  # For AUC\n",
    "\n",
    "    accuracy_score_list_val.append(accuracy_score(y_test, np.round(y_pred_proba)))\n",
    "    precision_score_list_val.append(precision_score(y_test, np.round(y_pred_proba)))\n",
    "    recall_score_list_val.append(recall_score(y_test, np.round(y_pred_proba)))\n",
    "    auc_score_list_val.append(roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:43:51.285031Z",
     "iopub.status.busy": "2024-06-29T10:43:51.284677Z",
     "iopub.status.idle": "2024-06-29T10:43:51.290732Z",
     "shell.execute_reply": "2024-06-29T10:43:51.290080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC: 0.7968472812125663\n",
      "Average Accuracy: 0.737152361030143\n",
      "Average Precision: 0.6866192356113968\n",
      "Average Recall: 0.6118924972004478\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Average AUC: {np.mean(auc_score_list_val)}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_score_list_val)}\")\n",
    "print(f\"Average Precision: {np.mean(precision_score_list_val)}\")\n",
    "print(f\"Average Recall: {np.mean(recall_score_list_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing with knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:43:51.293370Z",
     "iopub.status.busy": "2024-06-29T10:43:51.293205Z",
     "iopub.status.idle": "2024-06-29T11:13:09.446518Z",
     "shell.execute_reply": "2024-06-29T11:13:09.445937Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from utils.prepare_data import normalizeAndFillData\n",
    "\n",
    "\n",
    "accuracy_score_list_val_knn = []\n",
    "precision_score_list_val_knn = []\n",
    "recall_score_list_val_knn = []\n",
    "auc_score_list_val_knn = []\n",
    "metric_dic_list_val_knn = []\n",
    "for trainPatients, valPatients, testPatients in trainValTest():\n",
    "    dfTrain = trainPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfTrain = dfTrain.drop(columns=idColumns)\n",
    "\n",
    "    dfVal = valPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfVal = dfVal.drop(columns=idColumns)\n",
    "\n",
    "    dfTest = testPatients.getMeasuresBetween(\n",
    "        pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how, getUntilAkiPositive=True\n",
    "    )\n",
    "    dfTest = dfTest.drop(columns=idColumns)\n",
    "\n",
    "    dfTrain, dfTest, dfVal = normalizeAndFillData(dfTrain, dfTest, dfVal)\n",
    "\n",
    "    X_train = dfTrain.drop(columns=[labelColumn])\n",
    "    y_train = dfTrain[labelColumn]\n",
    "\n",
    "    X_val = dfVal.drop(columns=[labelColumn])  # type: ignore\n",
    "    y_val = dfVal[labelColumn]  # type: ignore\n",
    "\n",
    "    X_test = dfTest.drop(columns=[labelColumn])\n",
    "    y_test = dfTest[labelColumn]\n",
    "\n",
    "    model = createModel()\n",
    "    model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "    # y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict(X_test)[:, 1]  # For AUC\n",
    "\n",
    "    accuracy_score_list_val_knn.append(accuracy_score(y_test, np.round(y_pred_proba)))\n",
    "    precision_score_list_val_knn.append(precision_score(y_test, np.round(y_pred_proba)))\n",
    "    recall_score_list_val_knn.append(recall_score(y_test, np.round(y_pred_proba)))\n",
    "    auc_score_list_val_knn.append(roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T11:13:09.449352Z",
     "iopub.status.busy": "2024-06-29T11:13:09.449149Z",
     "iopub.status.idle": "2024-06-29T11:13:09.452244Z",
     "shell.execute_reply": "2024-06-29T11:13:09.451820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC: 0.7950410293126746\n",
      "Average Accuracy: 0.7255341037687323\n",
      "Average Precision: 0.6604147782746388\n",
      "Average Recall: 0.6245912653975364\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average AUC: {np.mean(auc_score_list_val_knn)}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_score_list_val_knn)}\")\n",
    "print(f\"Average Precision: {np.mean(precision_score_list_val_knn)}\")\n",
    "print(f\"Average Recall: {np.mean(recall_score_list_val_knn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param tune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T11:13:09.456343Z",
     "iopub.status.busy": "2024-06-29T11:13:09.455447Z",
     "iopub.status.idle": "2024-06-29T11:13:09.461190Z",
     "shell.execute_reply": "2024-06-29T11:13:09.460321Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# class GRANDEWrapper(BaseEstimator, ClassifierMixin):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         self.params = kwargs\n",
    "#         self.args = {\n",
    "#             \"device\": \"gpu\",  # device {'cpu', 'gpu'}\n",
    "#             \"epochs\": 1_000,  # number of epochs for training\n",
    "#             \"early_stopping_epochs\": 25,  # patience for early stopping (best weights are restored)\n",
    "#             \"batch_size\": 64,  # batch size for training\n",
    "#             \"cat_idx\": [],  # put list of categorical indices\n",
    "#             \"objective\": \"binary\",  # objective / task {'binary', 'classification', 'regression'}\n",
    "#             \"random_seed\": 42,\n",
    "#             \"verbose\": 0,\n",
    "#         }\n",
    "#         self.model = None\n",
    "\n",
    "#     def set_params(self, **params):\n",
    "#         for key, value in params.items():\n",
    "#             self.params[key] = value\n",
    "#         return self\n",
    "\n",
    "#     def get_params(self, deep=True):\n",
    "#         return self.params\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         self.classes_ = np.unique(y)\n",
    "\n",
    "#         X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=self.args[\"random_seed\"])\n",
    "\n",
    "#         self.model = GRANDE(params=self.params, args=self.args)\n",
    "#         self.model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "#         return self\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         if self.model is None:\n",
    "#             raise Exception(\"Model has not been trained yet!\")\n",
    "#         return self.model.predict(X)\n",
    "\n",
    "#     def predict_proba(self, X):\n",
    "#         if self.model is None:\n",
    "#             raise Exception(\"Model has not been trained yet!\")\n",
    "#         return self.model.predict(X)\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         y_pred_proba = self.predict_proba(X)[:, 1]  # For binary classification\n",
    "#         return roc_auc_score(y, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T11:13:09.463624Z",
     "iopub.status.busy": "2024-06-29T11:13:09.463330Z",
     "iopub.status.idle": "2024-06-29T11:13:09.469364Z",
     "shell.execute_reply": "2024-06-29T11:13:09.465612Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from utils.prepare_data import normalizeData\n",
    "\n",
    "\n",
    "# paramGrid = {\n",
    "#     \"params__device\"\n",
    "#     \"params__depth\": [4, 6, 8],\n",
    "#     \"params__n_estimators\": [500, 1000, 1500],\n",
    "#     \"params__learning_rate_weights\": [0.001, 0.005, 0.01],\n",
    "#     \"params__learning_rate_index\": [0.005, 0.01, 0.05],\n",
    "#     \"params__learning_rate_values\": [0.005, 0.01, 0.05],\n",
    "#     \"params__learning_rate_leaf\": [0.005, 0.01, 0.05],\n",
    "#     \"params__optimizer\": [\"adam\", \"sgd\"],\n",
    "#     \"params__cosine_decay_steps\": [0, 100, 500],\n",
    "#     \"params__loss\": [\"crossentropy\", \"mse\"],\n",
    "#     \"params__focal_loss\": [True, False],\n",
    "#     \"params__temperature\": [0.0, 0.1, 0.5],\n",
    "#     \"params__from_logits\": [True, False],\n",
    "#     \"params__use_class_weights\": [True, False],\n",
    "#     \"params__dropout\": [0.0, 0.1, 0.5],\n",
    "#     \"params__selected_variables\": [0.6, 0.8, 1.0],\n",
    "#     \"params__data_subset_fraction\": [0.8, 1.0],\n",
    "# }\n",
    "\n",
    "\n",
    "# gridModel = GRANDEWrapper()\n",
    "# gridSearch = GridSearchCV(\n",
    "#     estimator=gridModel,\n",
    "#     param_grid=paramGrid,\n",
    "#     scoring=\"roc_auc\",\n",
    "#     cv=5,\n",
    "#     verbose=2,\n",
    "#     n_jobs=3,\n",
    "# )\n",
    "\n",
    "# dfAll = patients.getMeasuresBetween(\n",
    "#     pd.Timedelta(hours=-6), pd.Timedelta(hours=24), how\n",
    "# )\n",
    "# dfAll = dfAll.drop(columns=idColumns)\n",
    "# dfAll, _, _ = normalizeData(dfAll, dfAll)\n",
    "# X_all = dfAll.drop(columns=[labelColumn])\n",
    "# y_all = dfAll[labelColumn]\n",
    "\n",
    "# gridSearch.fit(X_all, y_all)\n",
    "\n",
    "# print(\"Params\", gridSearch.best_params_)\n",
    "# print(\"Scores\", gridSearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998716a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
